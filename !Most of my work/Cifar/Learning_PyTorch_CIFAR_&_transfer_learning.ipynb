{
  "nbformat": 4,
  "nbformat_minor": 0,
  "metadata": {
    "colab": {
      "name": "Learning PyTorch - CIFAR & transfer learning",
      "provenance": [],
      "collapsed_sections": [],
      "authorship_tag": "ABX9TyPzNZF/iYQPsDwHdqs8/Jim"
    },
    "kernelspec": {
      "name": "python3",
      "display_name": "Python 3"
    },
    "accelerator": "GPU",
    "widgets": {
      "application/vnd.jupyter.widget-state+json": {
        "54da501330014900b07f9a71d5da6654": {
          "model_module": "@jupyter-widgets/controls",
          "model_name": "HBoxModel",
          "state": {
            "_view_name": "HBoxView",
            "_dom_classes": [],
            "_model_name": "HBoxModel",
            "_view_module": "@jupyter-widgets/controls",
            "_model_module_version": "1.5.0",
            "_view_count": null,
            "_view_module_version": "1.5.0",
            "box_style": "",
            "layout": "IPY_MODEL_26406a3d628c4398a7e8167fb643f143",
            "_model_module": "@jupyter-widgets/controls",
            "children": [
              "IPY_MODEL_586183a5f10d4f53b18e3d931d1f6bb9",
              "IPY_MODEL_b1a43b83fa654a0c9619d11ebb497212"
            ]
          }
        },
        "26406a3d628c4398a7e8167fb643f143": {
          "model_module": "@jupyter-widgets/base",
          "model_name": "LayoutModel",
          "state": {
            "_view_name": "LayoutView",
            "grid_template_rows": null,
            "right": null,
            "justify_content": null,
            "_view_module": "@jupyter-widgets/base",
            "overflow": null,
            "_model_module_version": "1.2.0",
            "_view_count": null,
            "flex_flow": null,
            "width": null,
            "min_width": null,
            "border": null,
            "align_items": null,
            "bottom": null,
            "_model_module": "@jupyter-widgets/base",
            "top": null,
            "grid_column": null,
            "overflow_y": null,
            "overflow_x": null,
            "grid_auto_flow": null,
            "grid_area": null,
            "grid_template_columns": null,
            "flex": null,
            "_model_name": "LayoutModel",
            "justify_items": null,
            "grid_row": null,
            "max_height": null,
            "align_content": null,
            "visibility": null,
            "align_self": null,
            "height": null,
            "min_height": null,
            "padding": null,
            "grid_auto_rows": null,
            "grid_gap": null,
            "max_width": null,
            "order": null,
            "_view_module_version": "1.2.0",
            "grid_template_areas": null,
            "object_position": null,
            "object_fit": null,
            "grid_auto_columns": null,
            "margin": null,
            "display": null,
            "left": null
          }
        },
        "586183a5f10d4f53b18e3d931d1f6bb9": {
          "model_module": "@jupyter-widgets/controls",
          "model_name": "FloatProgressModel",
          "state": {
            "_view_name": "ProgressView",
            "style": "IPY_MODEL_b2bda3f932924239acdfcd1a6cf13775",
            "_dom_classes": [],
            "description": "",
            "_model_name": "FloatProgressModel",
            "bar_style": "info",
            "max": 1,
            "_view_module": "@jupyter-widgets/controls",
            "_model_module_version": "1.5.0",
            "value": 1,
            "_view_count": null,
            "_view_module_version": "1.5.0",
            "orientation": "horizontal",
            "min": 0,
            "description_tooltip": null,
            "_model_module": "@jupyter-widgets/controls",
            "layout": "IPY_MODEL_7c67bc910bfe4f31bd5a1c600ea511c8"
          }
        },
        "b1a43b83fa654a0c9619d11ebb497212": {
          "model_module": "@jupyter-widgets/controls",
          "model_name": "HTMLModel",
          "state": {
            "_view_name": "HTMLView",
            "style": "IPY_MODEL_8a9e66a741894189bc2b0324b8ec70eb",
            "_dom_classes": [],
            "description": "",
            "_model_name": "HTMLModel",
            "placeholder": "â€‹",
            "_view_module": "@jupyter-widgets/controls",
            "_model_module_version": "1.5.0",
            "value": " 170500096/? [00:20&lt;00:00, 53878576.26it/s]",
            "_view_count": null,
            "_view_module_version": "1.5.0",
            "description_tooltip": null,
            "_model_module": "@jupyter-widgets/controls",
            "layout": "IPY_MODEL_aa81b97290714c738e074641616684ef"
          }
        },
        "b2bda3f932924239acdfcd1a6cf13775": {
          "model_module": "@jupyter-widgets/controls",
          "model_name": "ProgressStyleModel",
          "state": {
            "_view_name": "StyleView",
            "_model_name": "ProgressStyleModel",
            "description_width": "initial",
            "_view_module": "@jupyter-widgets/base",
            "_model_module_version": "1.5.0",
            "_view_count": null,
            "_view_module_version": "1.2.0",
            "bar_color": null,
            "_model_module": "@jupyter-widgets/controls"
          }
        },
        "7c67bc910bfe4f31bd5a1c600ea511c8": {
          "model_module": "@jupyter-widgets/base",
          "model_name": "LayoutModel",
          "state": {
            "_view_name": "LayoutView",
            "grid_template_rows": null,
            "right": null,
            "justify_content": null,
            "_view_module": "@jupyter-widgets/base",
            "overflow": null,
            "_model_module_version": "1.2.0",
            "_view_count": null,
            "flex_flow": null,
            "width": null,
            "min_width": null,
            "border": null,
            "align_items": null,
            "bottom": null,
            "_model_module": "@jupyter-widgets/base",
            "top": null,
            "grid_column": null,
            "overflow_y": null,
            "overflow_x": null,
            "grid_auto_flow": null,
            "grid_area": null,
            "grid_template_columns": null,
            "flex": null,
            "_model_name": "LayoutModel",
            "justify_items": null,
            "grid_row": null,
            "max_height": null,
            "align_content": null,
            "visibility": null,
            "align_self": null,
            "height": null,
            "min_height": null,
            "padding": null,
            "grid_auto_rows": null,
            "grid_gap": null,
            "max_width": null,
            "order": null,
            "_view_module_version": "1.2.0",
            "grid_template_areas": null,
            "object_position": null,
            "object_fit": null,
            "grid_auto_columns": null,
            "margin": null,
            "display": null,
            "left": null
          }
        },
        "8a9e66a741894189bc2b0324b8ec70eb": {
          "model_module": "@jupyter-widgets/controls",
          "model_name": "DescriptionStyleModel",
          "state": {
            "_view_name": "StyleView",
            "_model_name": "DescriptionStyleModel",
            "description_width": "",
            "_view_module": "@jupyter-widgets/base",
            "_model_module_version": "1.5.0",
            "_view_count": null,
            "_view_module_version": "1.2.0",
            "_model_module": "@jupyter-widgets/controls"
          }
        },
        "aa81b97290714c738e074641616684ef": {
          "model_module": "@jupyter-widgets/base",
          "model_name": "LayoutModel",
          "state": {
            "_view_name": "LayoutView",
            "grid_template_rows": null,
            "right": null,
            "justify_content": null,
            "_view_module": "@jupyter-widgets/base",
            "overflow": null,
            "_model_module_version": "1.2.0",
            "_view_count": null,
            "flex_flow": null,
            "width": null,
            "min_width": null,
            "border": null,
            "align_items": null,
            "bottom": null,
            "_model_module": "@jupyter-widgets/base",
            "top": null,
            "grid_column": null,
            "overflow_y": null,
            "overflow_x": null,
            "grid_auto_flow": null,
            "grid_area": null,
            "grid_template_columns": null,
            "flex": null,
            "_model_name": "LayoutModel",
            "justify_items": null,
            "grid_row": null,
            "max_height": null,
            "align_content": null,
            "visibility": null,
            "align_self": null,
            "height": null,
            "min_height": null,
            "padding": null,
            "grid_auto_rows": null,
            "grid_gap": null,
            "max_width": null,
            "order": null,
            "_view_module_version": "1.2.0",
            "grid_template_areas": null,
            "object_position": null,
            "object_fit": null,
            "grid_auto_columns": null,
            "margin": null,
            "display": null,
            "left": null
          }
        }
      }
    }
  },
  "cells": [
    {
      "cell_type": "code",
      "metadata": {
        "id": "ejpeeeJmksQc",
        "colab_type": "code",
        "colab": {}
      },
      "source": [
        "from __future__ import print_function\n",
        "import argparse\n",
        "import torch\n",
        "import torch.nn as nn\n",
        "import torch.nn.functional as F\n",
        "import torch.optim as optim\n",
        "\n",
        "import torchvision\n",
        "from torchvision import datasets, transforms\n",
        "import matplotlib.pyplot as plt\n",
        "import numpy as np"
      ],
      "execution_count": 1,
      "outputs": []
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "Fuaj_C4KI-kf",
        "colab_type": "text"
      },
      "source": [
        "# CNN"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "CVdjRIeCINLy",
        "colab_type": "text"
      },
      "source": [
        "## CIFAR10"
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "aj6p899BJ37f",
        "colab_type": "code",
        "colab": {
          "base_uri": "https://localhost:8080/",
          "height": 1000,
          "referenced_widgets": [
            "54da501330014900b07f9a71d5da6654",
            "26406a3d628c4398a7e8167fb643f143",
            "586183a5f10d4f53b18e3d931d1f6bb9",
            "b1a43b83fa654a0c9619d11ebb497212",
            "b2bda3f932924239acdfcd1a6cf13775",
            "7c67bc910bfe4f31bd5a1c600ea511c8",
            "8a9e66a741894189bc2b0324b8ec70eb",
            "aa81b97290714c738e074641616684ef"
          ]
        },
        "outputId": "7a08f0fd-8e1f-4996-b5c7-703b2eb85743"
      },
      "source": [
        "class Net(nn.Module):\n",
        "    def __init__(self):\n",
        "        super(Net, self).__init__()\n",
        "        # in , out, kernal (window), stride (movement)\n",
        "        self.conv1 = nn.Conv2d(3, 64, 5, 1)\n",
        "        self.conv2 = nn.Conv2d(64, 128, 3, 1)\n",
        "        self.conv3 = nn.Conv2d(128, 128, 3, 1)\n",
        "        self.dropout1 = nn.Dropout2d(0.25)\n",
        "        self.dropout2 = nn.Dropout2d(0.5)\n",
        "        # max pooling gives 1/4th the parameters\n",
        "        self.fc1 = nn.Linear(3200, 1028)\n",
        "        self.fc2 = nn.Linear(1028, 100)\n",
        "\n",
        "    def forward(self, x):\n",
        "        x = self.conv1(x)\n",
        "        x = F.relu(x)\n",
        "        x = self.conv2(x)\n",
        "        x = F.relu(x)\n",
        "        x = F.max_pool2d(x, 2)  # a 2 by 2 window becomes a single value\n",
        "        x = self.conv3(x)\n",
        "        x = F.relu(x)\n",
        "        x = F.max_pool2d(x, 2)\n",
        "        # x = self.dropout1(x)\n",
        "        x = torch.flatten(x, 1)\n",
        "        x = self.fc1(x)\n",
        "        x = F.relu(x)\n",
        "        # x = self.dropout2(x)\n",
        "        x = self.fc2(x)\n",
        "        output = F.log_softmax(x, dim=1)\n",
        "        return output\n",
        "\n",
        "\n",
        "def train(model, device, train_loader, optimizer, epoch):\n",
        "    model.train()\n",
        "    for batch_idx, (data, target) in enumerate(train_loader):\n",
        "        data, target = data.to(device), target.to(device)\n",
        "        optimizer.zero_grad()\n",
        "        output = model(data)\n",
        "        loss = F.nll_loss(output, target)\n",
        "        loss.backward()\n",
        "        optimizer.step()\n",
        "        if batch_idx % 500 == 0:\n",
        "            print('Train Epoch: {} [{}/{} ({:.0f}%)]\\tLoss: {:.6f}'.format(\n",
        "                epoch, batch_idx * len(data), len(train_loader.dataset),\n",
        "                100. * batch_idx / len(train_loader), loss.item()))\n",
        "\n",
        "\n",
        "def test(model, device, test_loader):\n",
        "    model.eval()\n",
        "    test_loss = 0\n",
        "    correct = 0\n",
        "    with torch.no_grad():\n",
        "        for data, target in test_loader:\n",
        "            data, target = data.to(device), target.to(device)\n",
        "            output = model(data)\n",
        "            # sum up batch loss\n",
        "            test_loss += F.nll_loss(output, target, reduction='sum').item()\n",
        "            # get the index of the max log-probability\n",
        "            pred = output.argmax(dim=1, keepdim=True)\n",
        "            correct += pred.eq(target.view_as(pred)).sum().item()\n",
        "\n",
        "    test_loss /= len(test_loader.dataset)\n",
        "\n",
        "    print('\\nTest set: Average loss: {:.4f}, Accuracy: {}/{} ({:.0f}%)\\n'.format(\n",
        "        test_loss, correct, len(test_loader.dataset),\n",
        "        100. * correct / len(test_loader.dataset)))\n",
        "\n",
        "\n",
        "def main():\n",
        "    epochs = 10\n",
        "    step_size = 3 # LR reduce\n",
        "    torch.manual_seed(42)\n",
        "    use_cuda = torch.cuda.is_available()\n",
        "    device = torch.device(\"cuda\" if use_cuda else \"cpu\")\n",
        "\n",
        "    kwargs = {'batch_size': 32}\n",
        "    if use_cuda:\n",
        "        kwargs.update({'num_workers': 1,\n",
        "                       'pin_memory': True,\n",
        "                       'shuffle': True})\n",
        "\n",
        "    transform = transforms.Compose(\n",
        "        [transforms.ToTensor(),\n",
        "         transforms.Normalize((0.5, 0.5, 0.5), (0.5, 0.5, 0.5))])\n",
        "    dataset1 = datasets.CIFAR10('./data', train=True, download=True,\n",
        "                                transform=transform)\n",
        "    dataset2 = datasets.CIFAR10('./data', train=False,\n",
        "                                transform=transform)\n",
        "    train_loader = torch.utils.data.DataLoader(dataset1, **kwargs)\n",
        "    test_loader = torch.utils.data.DataLoader(dataset2, **kwargs)\n",
        "\n",
        "    model = Net().to(device)\n",
        "    optimizer = optim.Adam(model.parameters())\n",
        "\n",
        "    scheduler = optim.lr_scheduler.StepLR(optimizer, step_size=step_size)\n",
        "    for epoch in range(1, epochs + 1):\n",
        "        train(model, device, train_loader, optimizer, epoch)\n",
        "        test(model, device, test_loader)\n",
        "        scheduler.step()\n",
        "\n",
        "    # torch.save(model.state_dict(), \"mnist_cnn.pt\")\n",
        "    print('Saved*')\n",
        "\n",
        "\n",
        "if __name__ == '__main__':\n",
        "    main()\n"
      ],
      "execution_count": 2,
      "outputs": [
        {
          "output_type": "stream",
          "text": [
            "Downloading https://www.cs.toronto.edu/~kriz/cifar-10-python.tar.gz to ./data/cifar-10-python.tar.gz\n"
          ],
          "name": "stdout"
        },
        {
          "output_type": "display_data",
          "data": {
            "application/vnd.jupyter.widget-view+json": {
              "model_id": "54da501330014900b07f9a71d5da6654",
              "version_minor": 0,
              "version_major": 2
            },
            "text/plain": [
              "HBox(children=(FloatProgress(value=1.0, bar_style='info', max=1.0), HTML(value='')))"
            ]
          },
          "metadata": {
            "tags": []
          }
        },
        {
          "output_type": "stream",
          "text": [
            "Extracting ./data/cifar-10-python.tar.gz to ./data\n",
            "Train Epoch: 1 [0/50000 (0%)]\tLoss: 4.601831\n",
            "Train Epoch: 1 [16000/50000 (32%)]\tLoss: 1.228391\n",
            "Train Epoch: 1 [32000/50000 (64%)]\tLoss: 1.243555\n",
            "Train Epoch: 1 [48000/50000 (96%)]\tLoss: 1.200248\n",
            "\n",
            "Test set: Average loss: 1.1098, Accuracy: 6070/10000 (61%)\n",
            "\n",
            "Train Epoch: 2 [0/50000 (0%)]\tLoss: 1.041132\n",
            "Train Epoch: 2 [16000/50000 (32%)]\tLoss: 1.187556\n",
            "Train Epoch: 2 [32000/50000 (64%)]\tLoss: 0.613937\n",
            "Train Epoch: 2 [48000/50000 (96%)]\tLoss: 0.749840\n",
            "\n",
            "Test set: Average loss: 0.9150, Accuracy: 6856/10000 (69%)\n",
            "\n",
            "Train Epoch: 3 [0/50000 (0%)]\tLoss: 0.449399\n",
            "Train Epoch: 3 [16000/50000 (32%)]\tLoss: 0.380663\n",
            "Train Epoch: 3 [32000/50000 (64%)]\tLoss: 0.725610\n",
            "Train Epoch: 3 [48000/50000 (96%)]\tLoss: 0.324543\n",
            "\n",
            "Test set: Average loss: 0.8363, Accuracy: 7246/10000 (72%)\n",
            "\n",
            "Train Epoch: 4 [0/50000 (0%)]\tLoss: 0.409861\n",
            "Train Epoch: 4 [16000/50000 (32%)]\tLoss: 0.321897\n",
            "Train Epoch: 4 [32000/50000 (64%)]\tLoss: 0.237785\n",
            "Train Epoch: 4 [48000/50000 (96%)]\tLoss: 0.096928\n",
            "\n",
            "Test set: Average loss: 0.7863, Accuracy: 7600/10000 (76%)\n",
            "\n",
            "Train Epoch: 5 [0/50000 (0%)]\tLoss: 0.228007\n",
            "Train Epoch: 5 [16000/50000 (32%)]\tLoss: 0.154865\n",
            "Train Epoch: 5 [32000/50000 (64%)]\tLoss: 0.257893\n",
            "Train Epoch: 5 [48000/50000 (96%)]\tLoss: 0.325022\n",
            "\n",
            "Test set: Average loss: 0.8429, Accuracy: 7564/10000 (76%)\n",
            "\n",
            "Train Epoch: 6 [0/50000 (0%)]\tLoss: 0.170314\n",
            "Train Epoch: 6 [16000/50000 (32%)]\tLoss: 0.217685\n",
            "Train Epoch: 6 [32000/50000 (64%)]\tLoss: 0.418139\n",
            "Train Epoch: 6 [48000/50000 (96%)]\tLoss: 0.361566\n",
            "\n",
            "Test set: Average loss: 0.9168, Accuracy: 7591/10000 (76%)\n",
            "\n",
            "Train Epoch: 7 [0/50000 (0%)]\tLoss: 0.051355\n",
            "Train Epoch: 7 [16000/50000 (32%)]\tLoss: 0.064925\n",
            "Train Epoch: 7 [32000/50000 (64%)]\tLoss: 0.059069\n",
            "Train Epoch: 7 [48000/50000 (96%)]\tLoss: 0.062702\n",
            "\n",
            "Test set: Average loss: 0.9436, Accuracy: 7617/10000 (76%)\n",
            "\n",
            "Train Epoch: 8 [0/50000 (0%)]\tLoss: 0.065058\n",
            "Train Epoch: 8 [16000/50000 (32%)]\tLoss: 0.071581\n",
            "Train Epoch: 8 [32000/50000 (64%)]\tLoss: 0.089197\n",
            "Train Epoch: 8 [48000/50000 (96%)]\tLoss: 0.042435\n",
            "\n",
            "Test set: Average loss: 0.9659, Accuracy: 7616/10000 (76%)\n",
            "\n",
            "Train Epoch: 9 [0/50000 (0%)]\tLoss: 0.086180\n",
            "Train Epoch: 9 [16000/50000 (32%)]\tLoss: 0.046337\n",
            "Train Epoch: 9 [32000/50000 (64%)]\tLoss: 0.025377\n",
            "Train Epoch: 9 [48000/50000 (96%)]\tLoss: 0.037807\n",
            "\n",
            "Test set: Average loss: 0.9899, Accuracy: 7611/10000 (76%)\n",
            "\n",
            "Train Epoch: 10 [0/50000 (0%)]\tLoss: 0.047146\n",
            "Train Epoch: 10 [16000/50000 (32%)]\tLoss: 0.159925\n",
            "Train Epoch: 10 [32000/50000 (64%)]\tLoss: 0.122234\n",
            "Train Epoch: 10 [48000/50000 (96%)]\tLoss: 0.122462\n",
            "\n",
            "Test set: Average loss: 0.9905, Accuracy: 7610/10000 (76%)\n",
            "\n",
            "Saved*\n"
          ],
          "name": "stdout"
        }
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "ZfFbOlwUvs0a",
        "colab_type": "text"
      },
      "source": [
        "### Secound Cifar 10 model"
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "aaVy_nTEvtar",
        "colab_type": "code",
        "colab": {
          "base_uri": "https://localhost:8080/",
          "height": 822
        },
        "outputId": "a74c5fd7-f655-415d-ccd5-4420a84defd0"
      },
      "source": [
        "# adapted from https://github.com/python-engineer/pytorchTutorial/blob/master/14_cnn.py\n",
        "\n",
        "# Device configuration\n",
        "device = torch.device('cuda' if torch.cuda.is_available() else 'cpu')\n",
        "\n",
        "# Hyper-parameters \n",
        "num_epochs = 10\n",
        "batch_size = 8\n",
        "learning_rate = 0.001 # 0.001\n",
        "step_size = 4\n",
        "\n",
        "# dataset has PILImage images of range [0, 1]. \n",
        "# We transform them to Tensors of normalized range [-1, 1]\n",
        "transform = transforms.Compose(\n",
        "    [transforms.ToTensor(),\n",
        "     transforms.Normalize((0.5, 0.5, 0.5), (0.5, 0.5, 0.5))])\n",
        "\n",
        "# CIFAR10: 60000 32x32 color images in 10 classes, with 6000 images per class\n",
        "train_dataset = datasets.CIFAR10(root='./data', train=True,\n",
        "                                        download=True, transform=transform)\n",
        "\n",
        "test_dataset = datasets.CIFAR10(root='./data', train=False,\n",
        "                                       download=True, transform=transform)\n",
        "\n",
        "train_loader = torch.utils.data.DataLoader(train_dataset, batch_size=batch_size,\n",
        "                                          shuffle=True)\n",
        "\n",
        "test_loader = torch.utils.data.DataLoader(test_dataset, batch_size=batch_size,\n",
        "                                         shuffle=False)\n",
        "\n",
        "classes = ('plane', 'car', 'bird', 'cat',\n",
        "           'deer', 'dog', 'frog', 'horse', 'ship', 'truck')\n",
        "\n",
        "def imshow(img):\n",
        "    img = img / 2 + 0.5  # unnormalize\n",
        "    npimg = img.numpy()\n",
        "    plt.imshow(np.transpose(npimg, (1, 2, 0)))\n",
        "    plt.show()\n",
        "\n",
        "# get some random training images\n",
        "dataiter = iter(train_loader)\n",
        "images, labels = dataiter.next()\n",
        "\n",
        "# show images\n",
        "imshow(torchvision.utils.make_grid(images))\n",
        "\n",
        "class ConvNet(nn.Module):\n",
        "    def __init__(self):\n",
        "        super(ConvNet, self).__init__()\n",
        "        self.conv1 = nn.Conv2d(3, 6, 5)\n",
        "        self.pool = nn.MaxPool2d(2, 2)\n",
        "        self.conv2 = nn.Conv2d(6, 16, 5)\n",
        "        self.fc1 = nn.Linear(16 * 5 * 5, 120)\n",
        "        self.fc2 = nn.Linear(120, 84)\n",
        "        self.fc3 = nn.Linear(84, 10)\n",
        "\n",
        "    def forward(self, x):\n",
        "        # -> n, 3, 32, 32\n",
        "        x = self.pool(F.relu(self.conv1(x)))  # -> n, 6, 14, 14\n",
        "        x = self.pool(F.relu(self.conv2(x)))  # -> n, 16, 5, 5\n",
        "        x = x.view(-1, 16 * 5 * 5)            # -> n, 400       # (1, output * kernal * kernal)\n",
        "        x = F.relu(self.fc1(x))               # -> n, 120\n",
        "        x = F.relu(self.fc2(x))               # -> n, 84\n",
        "        x = self.fc3(x)                       # -> n, 10\n",
        "        return x\n",
        "\n",
        "\n",
        "model = ConvNet().to(device)\n",
        "\n",
        "criterion = nn.CrossEntropyLoss()\n",
        "optimizer = optim.Adam(params=model.parameters(), lr=learning_rate)\n",
        "# scheduler = optim.lr_scheduler.ReduceLROnPlateau(optimizer, patience=1, factor=0.5)\n",
        "# scheduler = optim.lr_scheduler.StepLR(optimizer=optimizer, step_size=step_size, gamma=0.5)\n",
        "\n",
        "n_total_steps = len(train_loader)\n",
        "MIN_LOSS = 9999999\n",
        "SAVE_PATH = './cnn.pth'\n",
        "for epoch in range(num_epochs):\n",
        "    for i, (images, labels) in enumerate(train_loader):\n",
        "        # origin shape: [4, 3, 32, 32] = 4, 3, 1024\n",
        "        # input_layer: 3 input channels, 6 output channels, 5 kernel size\n",
        "        images = images.to(device)\n",
        "        labels = labels.to(device)\n",
        "\n",
        "        # Forward pass\n",
        "        outputs = model(images)\n",
        "        global loss\n",
        "        loss = criterion(outputs, labels)\n",
        "\n",
        "        # Backward and optimize\n",
        "        optimizer.zero_grad()\n",
        "        loss.backward()\n",
        "        optimizer.step()\n",
        "\n",
        "        if (i+1) % 3125 == 0:\n",
        "            lr = optimizer.param_groups[0]['lr']\n",
        "            print(f'Epoch [{epoch+1}/{num_epochs}], Step [{i+1}/{n_total_steps}], Loss: {loss.item():.4f}, Loss: {lr}')\n",
        "            if loss.item() < MIN_LOSS:\n",
        "              MIN_LOSS = loss.item()\n",
        "              torch.save({\n",
        "                          'epoch': epoch,\n",
        "                          'learning_rate': lr,\n",
        "                          'loss': loss.item(), # not the OBJ\n",
        "                          'model_state_dict': model.state_dict(),\n",
        "                          'optimizer_state_dict': optimizer.state_dict(),\n",
        "                          }, SAVE_PATH)\n",
        "              print(\"Model saved\")\n",
        "    pass # end of epoch \n",
        "    # scheduler.step()\n",
        "\n",
        "print('Finished Training')\n",
        "\n",
        "\n",
        "\n",
        "with torch.no_grad():\n",
        "    n_correct = 0\n",
        "    n_samples = 0\n",
        "    n_class_correct = [0 for i in range(10)]\n",
        "    n_class_samples = [0 for i in range(10)]\n",
        "    for images, labels in test_loader:\n",
        "        images = images.to(device)\n",
        "        labels = labels.to(device)\n",
        "        outputs = model(images)\n",
        "        # max returns (value ,index)\n",
        "        _, predicted = torch.max(outputs, 1)\n",
        "        n_samples += labels.size(0)\n",
        "        n_correct += (predicted == labels).sum().item()\n",
        "        \n",
        "        for i in range(batch_size):\n",
        "            label = labels[i]\n",
        "            pred = predicted[i]\n",
        "            if (label == pred):\n",
        "                n_class_correct[label] += 1\n",
        "            n_class_samples[label] += 1\n",
        "\n",
        "    acc = 100.0 * n_correct / n_samples\n",
        "    print(f'Accuracy of the network: {acc} %')\n",
        "\n",
        "    for i in range(10):\n",
        "        acc = 100.0 * n_class_correct[i] / n_class_samples[i]\n",
        "        print(f'Accuracy of {classes[i]}: {acc} %')\n"
      ],
      "execution_count": 11,
      "outputs": [
        {
          "output_type": "stream",
          "text": [
            "Files already downloaded and verified\n",
            "Files already downloaded and verified\n"
          ],
          "name": "stdout"
        },
        {
          "output_type": "display_data",
          "data": {
            "image/png": "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\n",
            "text/plain": [
              "<Figure size 432x288 with 1 Axes>"
            ]
          },
          "metadata": {
            "tags": [],
            "needs_background": "light"
          }
        },
        {
          "output_type": "stream",
          "text": [
            "Epoch [1/10], Step [3125/6250], Loss: 1.5743, Loss: 0.001\n",
            "Model saved\n",
            "Epoch [1/10], Step [6250/6250], Loss: 0.9756, Loss: 0.001\n",
            "Model saved\n",
            "Epoch [2/10], Step [3125/6250], Loss: 1.2423, Loss: 0.001\n",
            "Epoch [2/10], Step [6250/6250], Loss: 0.8610, Loss: 0.001\n",
            "Model saved\n",
            "Epoch [3/10], Step [3125/6250], Loss: 0.6053, Loss: 0.001\n",
            "Model saved\n",
            "Epoch [3/10], Step [6250/6250], Loss: 1.4957, Loss: 0.001\n",
            "Epoch [4/10], Step [3125/6250], Loss: 0.7863, Loss: 0.001\n",
            "Epoch [4/10], Step [6250/6250], Loss: 0.9809, Loss: 0.001\n",
            "Epoch [5/10], Step [3125/6250], Loss: 1.0818, Loss: 0.001\n",
            "Epoch [5/10], Step [6250/6250], Loss: 0.7098, Loss: 0.001\n",
            "Epoch [6/10], Step [3125/6250], Loss: 1.4608, Loss: 0.001\n",
            "Epoch [6/10], Step [6250/6250], Loss: 0.4044, Loss: 0.001\n",
            "Model saved\n",
            "Epoch [7/10], Step [3125/6250], Loss: 0.6990, Loss: 0.001\n",
            "Epoch [7/10], Step [6250/6250], Loss: 0.9097, Loss: 0.001\n",
            "Epoch [8/10], Step [3125/6250], Loss: 1.5360, Loss: 0.001\n",
            "Epoch [8/10], Step [6250/6250], Loss: 1.0049, Loss: 0.001\n",
            "Epoch [9/10], Step [3125/6250], Loss: 1.0035, Loss: 0.001\n",
            "Epoch [9/10], Step [6250/6250], Loss: 0.7562, Loss: 0.001\n",
            "Epoch [10/10], Step [3125/6250], Loss: 0.7778, Loss: 0.001\n",
            "Epoch [10/10], Step [6250/6250], Loss: 0.2628, Loss: 0.001\n",
            "Model saved\n",
            "Finished Training\n",
            "Accuracy of the network: 62.09 %\n",
            "Accuracy of plane: 68.7 %\n",
            "Accuracy of car: 76.0 %\n",
            "Accuracy of bird: 51.0 %\n",
            "Accuracy of cat: 43.0 %\n",
            "Accuracy of deer: 51.9 %\n",
            "Accuracy of dog: 46.0 %\n",
            "Accuracy of frog: 77.0 %\n",
            "Accuracy of horse: 66.1 %\n",
            "Accuracy of ship: 79.3 %\n",
            "Accuracy of truck: 61.9 %\n"
          ],
          "name": "stdout"
        }
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "TX1-RMhcvteM",
        "colab_type": "code",
        "colab": {
          "base_uri": "https://localhost:8080/",
          "height": 235
        },
        "outputId": "e32d22b8-8784-41e7-e947-1743f1e93711"
      },
      "source": [
        "print('Finished Training. Restoring best model')\n",
        "checkpoint = torch.load(SAVE_PATH)\n",
        "model.load_state_dict(checkpoint['model_state_dict'])\n",
        "optimizer.load_state_dict(checkpoint['optimizer_state_dict'])\n",
        "epoch = checkpoint['epoch']\n",
        "loss = checkpoint['loss']\n",
        "model.eval()\n",
        "\n",
        "with torch.no_grad():\n",
        "    n_correct = 0\n",
        "    n_samples = 0\n",
        "    n_class_correct = [0 for i in range(10)]\n",
        "    n_class_samples = [0 for i in range(10)]\n",
        "    for images, labels in test_loader:\n",
        "        images = images.to(device)\n",
        "        labels = labels.to(device)\n",
        "        outputs = model(images)\n",
        "        # max returns (value ,index)\n",
        "        _, predicted = torch.max(outputs, 1)\n",
        "        n_samples += labels.size(0)\n",
        "        n_correct += (predicted == labels).sum().item()\n",
        "\n",
        "        for i in range(batch_size):\n",
        "            label = labels[i]\n",
        "            pred = predicted[i]\n",
        "            if (label == pred):\n",
        "                n_class_correct[label] += 1\n",
        "            n_class_samples[label] += 1\n",
        "\n",
        "    acc = 100.0 * n_correct / n_samples\n",
        "    print(f'Accuracy of the network: {acc} %')\n",
        "\n",
        "    for i in range(10):\n",
        "        acc = 100.0 * n_class_correct[i] / n_class_samples[i]\n",
        "        print(f'Accuracy of {classes[i]}: {acc} %')\n"
      ],
      "execution_count": 12,
      "outputs": [
        {
          "output_type": "stream",
          "text": [
            "Finished Training. Restoring best model\n",
            "Accuracy of the network: 62.09 %\n",
            "Accuracy of plane: 68.7 %\n",
            "Accuracy of car: 76.0 %\n",
            "Accuracy of bird: 51.0 %\n",
            "Accuracy of cat: 43.0 %\n",
            "Accuracy of deer: 51.9 %\n",
            "Accuracy of dog: 46.0 %\n",
            "Accuracy of frog: 77.0 %\n",
            "Accuracy of horse: 66.1 %\n",
            "Accuracy of ship: 79.3 %\n",
            "Accuracy of truck: 61.9 %\n"
          ],
          "name": "stdout"
        }
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "n0X0Hxjrvtq8",
        "colab_type": "code",
        "colab": {}
      },
      "source": [
        ""
      ],
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "bgvXz-2yJHtT",
        "colab_type": "text"
      },
      "source": [
        "## ResNet\n",
        "\n",
        "Used: [Video](https://www.youtube.com/watch?v=DkNIBBBvcPs) | [Code](https://raw.githubusercontent.com/AladdinPerzon/Machine-Learning-Collection/master/ML/Pytorch/CNN_architectures/pytorch_resnet.py)"
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "rHln9GTNJMoH",
        "colab_type": "code",
        "colab": {}
      },
      "source": [
        "class block(nn.Module):\n",
        "    def __init__(self, in_channels, intermediate_channels, identity_downsample=None, stride=1):\n",
        "        super().__init__()\n",
        "        self.expansion = 4\n",
        "        self.conv1 = nn.Conv2d(\n",
        "            in_channels, intermediate_channels, kernel_size=1, stride=1, padding=0\n",
        "        )\n",
        "        self.bn1 = nn.BatchNorm2d(intermediate_channels)\n",
        "        self.conv2 = nn.Conv2d(\n",
        "            intermediate_channels,\n",
        "            intermediate_channels,\n",
        "            kernel_size=3,\n",
        "            stride=stride,\n",
        "            padding=1,\n",
        "        )\n",
        "        self.bn2 = nn.BatchNorm2d(intermediate_channels)\n",
        "        self.conv3 = nn.Conv2d(\n",
        "            intermediate_channels,\n",
        "            intermediate_channels * self.expansion,\n",
        "            kernel_size=1,\n",
        "            stride=1,\n",
        "            padding=0,\n",
        "        )\n",
        "        self.bn3 = nn.BatchNorm2d(intermediate_channels * self.expansion)\n",
        "        self.relu = nn.ReLU()\n",
        "        self.identity_downsample = identity_downsample\n",
        "        self.stride = stride\n",
        "\n",
        "    def forward(self, x):\n",
        "        identity = x.clone()\n",
        "\n",
        "        x = self.conv1(x)\n",
        "        x = self.bn1(x)\n",
        "        x = self.relu(x)\n",
        "        x = self.conv2(x)\n",
        "        x = self.bn2(x)\n",
        "        x = self.relu(x)\n",
        "        x = self.conv3(x)\n",
        "        x = self.bn3(x)\n",
        "\n",
        "        if self.identity_downsample is not None:\n",
        "            identity = self.identity_downsample(identity)\n",
        "\n",
        "        x += identity\n",
        "        x = self.relu(x)\n",
        "        return x"
      ],
      "execution_count": 6,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "XIJhNhiWJOMX",
        "colab_type": "code",
        "colab": {}
      },
      "source": [
        "class ResNet(nn.Module):\n",
        "    def __init__(self, block, layers, image_channels, num_classes):\n",
        "        super().__init__()\n",
        "        self.in_channels = 64\n",
        "        self.conv1 = nn.Conv2d(image_channels, out_channels=64, kernel_size=7, stride=2, padding=3)\n",
        "        self.bn1 = nn.BatchNorm2d(64)\n",
        "        self.relu = nn.ReLU()\n",
        "        self.maxpool = nn.MaxPool2d(kernel_size=3, stride=2, padding=1)\n",
        "\n",
        "        # Essentially the entire ResNet architecture are in these 4 lines below\n",
        "        self.layer1 = self._make_layer(\n",
        "            block, layers[0], intermediate_channels=64, stride=1\n",
        "        )\n",
        "        self.layer2 = self._make_layer(\n",
        "            block, layers[1], intermediate_channels=128, stride=2\n",
        "        )\n",
        "        self.layer3 = self._make_layer(\n",
        "            block, layers[2], intermediate_channels=256, stride=2\n",
        "        )\n",
        "        self.layer4 = self._make_layer(\n",
        "            block, layers[3], intermediate_channels=512, stride=2\n",
        "        )\n",
        "\n",
        "        self.avgpool = nn.AdaptiveAvgPool2d((1, 1))\n",
        "        self.fc = nn.Linear(512 * 4, num_classes)\n",
        "\n",
        "    def forward(self, x):\n",
        "        x = self.conv1(x)\n",
        "        x = self.bn1(x)\n",
        "        x = self.relu(x)\n",
        "        x = self.maxpool(x)\n",
        "        x = self.layer1(x)\n",
        "        x = self.layer2(x)\n",
        "        x = self.layer3(x)\n",
        "        x = self.layer4(x)\n",
        "\n",
        "        x = self.avgpool(x)\n",
        "        x = x.reshape(x.shape[0], -1)  # TODO why?\n",
        "        x = self.fc(x)\n",
        "\n",
        "        return x\n",
        "\n",
        "    def _make_layer(self, block, num_residual_blocks, intermediate_channels, stride):\n",
        "        identity_downsample = None\n",
        "        layers = []\n",
        "\n",
        "        # Either if we half the input space for ex, 56x56 -> 28x28 (stride=2), or channels changes\n",
        "        # we need to adapt the Identity (skip connection) so it will be able to be added\n",
        "        # to the layer that's ahead\n",
        "        if stride != 1 or self.in_channels != intermediate_channels * 4:\n",
        "            identity_downsample = nn.Sequential(\n",
        "                nn.Conv2d(\n",
        "                    self.in_channels,\n",
        "                    intermediate_channels * 4,\n",
        "                    kernel_size=1,\n",
        "                    stride=stride,\n",
        "                ),\n",
        "                nn.BatchNorm2d(intermediate_channels * 4),\n",
        "            )\n",
        "\n",
        "        layers.append(\n",
        "            block(self.in_channels, intermediate_channels, identity_downsample, stride)\n",
        "        )\n",
        "\n",
        "        # The expansion size is always 4 for ResNet 50,101,152\n",
        "        self.in_channels = intermediate_channels * 4\n",
        "\n",
        "        # For example for first resnet layer: 256 will be mapped to 64 as intermediate layer,\n",
        "        # then finally back to 256. Hence no identity downsample is needed, since stride = 1,\n",
        "        # and also same amount of channels.\n",
        "        for i in range(num_residual_blocks - 1):\n",
        "            layers.append(block(self.in_channels, intermediate_channels))\n",
        "\n",
        "        return nn.Sequential(*layers)"
      ],
      "execution_count": 7,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "pcnw-qGiJOPW",
        "colab_type": "code",
        "colab": {
          "base_uri": "https://localhost:8080/",
          "height": 35
        },
        "outputId": "4b79cc2f-15a6-4b73-e609-39f405385398"
      },
      "source": [
        "def ResNet50(img_channel=3, num_classes=1000):\n",
        "    return ResNet(block, [3, 4, 6, 3], img_channel, num_classes)\n",
        "\n",
        "def ResNet101(img_channel=3, num_classes=1000):\n",
        "    return ResNet(block, [3, 4, 23, 3], img_channel, num_classes)\n",
        "\n",
        "def ResNet152(img_channel=3, num_classes=1000):\n",
        "    return ResNet(block, [3, 8, 36, 3], img_channel, num_classes)\n",
        "\n",
        "net = ResNet50(img_channel=3, num_classes=10)\n",
        "y = net(torch.randn(10, 3, 224, 224)).to(\"cuda\")\n",
        "print(y.size())"
      ],
      "execution_count": 8,
      "outputs": [
        {
          "output_type": "stream",
          "text": [
            "torch.Size([10, 10])\n"
          ],
          "name": "stdout"
        }
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "juiNjzf7JOSX",
        "colab_type": "code",
        "colab": {
          "base_uri": "https://localhost:8080/",
          "height": 1000
        },
        "outputId": "7ba7f72f-c2d1-41db-dfca-f979f76c5945"
      },
      "source": [
        " def main():\n",
        "    epochs = 8\n",
        "    step_size = 3 # LR reduce\n",
        "    LR = 0.005\n",
        "    torch.manual_seed(42)\n",
        "    use_cuda = torch.cuda.is_available()\n",
        "    device = torch.device(\"cuda\" if use_cuda else \"cpu\")\n",
        "\n",
        "    kwargs = {'batch_size': 8}\n",
        "    if use_cuda:\n",
        "        kwargs.update({'num_workers': 1,\n",
        "                       'pin_memory': True,\n",
        "                       'shuffle': True})\n",
        "\n",
        "    transform = transforms.Compose(\n",
        "        [transforms.ToTensor(),\n",
        "         transforms.Normalize((0.5, 0.5, 0.5), (0.5, 0.5, 0.5))])\n",
        "    dataset1 = datasets.CIFAR10('./data', train=True, download=True,\n",
        "                                transform=transform)\n",
        "    dataset2 = datasets.CIFAR10('./data', train=False,\n",
        "                                transform=transform)\n",
        "    train_loader = torch.utils.data.DataLoader(dataset1, **kwargs)\n",
        "    test_loader = torch.utils.data.DataLoader(dataset2, **kwargs)\n",
        "\n",
        "    model = ResNet50(img_channel=3, num_classes=10).to(device)\n",
        "    optimizer = optim.Adam(model.parameters(), lr=LR)\n",
        "    scheduler = optim.lr_scheduler.StepLR(optimizer, step_size=step_size, gamma=0.1)\n",
        "    \n",
        "    for epoch in range(1, epochs + 1):\n",
        "        train(model, device, train_loader, optimizer, epoch)\n",
        "        test(model, device, test_loader)\n",
        "        scheduler.step()\n",
        "\n",
        "    print('Saved*')\n",
        "\n",
        "\n",
        "def train(model, device, train_loader, optimizer, epoch):\n",
        "    model.train()\n",
        "    for batch_idx, (data, target) in enumerate(train_loader):\n",
        "        data, target = data.to(device), target.to(device)\n",
        "        output = model(data)\n",
        "\n",
        "        # loss = criterion(outputs, labels) # CrossEntropyLoss  combines nn.LogSoftmax() and nn.NLLLoss() in one single class\n",
        "        loss = F.nll_loss(F.log_softmax(output, 1), target)\n",
        "        # Backward and optimize\n",
        "        optimizer.zero_grad()\n",
        "        loss.backward()\n",
        "        optimizer.step()\n",
        "        \n",
        "        if batch_idx % 500 == 0:\n",
        "            print('Train Epoch: {} [{}/{} ({:.0f}%)]\\tLoss: {:.6f}\\tLR: {}'.format(\n",
        "                epoch, batch_idx * len(data), len(train_loader.dataset),\n",
        "                100. * batch_idx / len(train_loader), loss.item(), \n",
        "                optimizer.param_groups[0]['lr']))\n",
        "\n",
        "\n",
        "def test(model, device, test_loader):\n",
        "    model.eval()\n",
        "    test_loss = 0\n",
        "    correct = 0\n",
        "    with torch.no_grad():\n",
        "        for data, target in test_loader:\n",
        "            data, target = data.to(device), target.to(device)\n",
        "            output = model(data)\n",
        "            # sum up batch loss\n",
        "            test_loss += F.nll_loss(F.log_softmax(output, 1), target, reduction='sum').item()\n",
        "            # get the index of the max log-probability\n",
        "            pred = output.argmax(dim=1, keepdim=True)\n",
        "            correct += pred.eq(target.view_as(pred)).sum().item()\n",
        "\n",
        "    test_loss /= len(test_loader.dataset)\n",
        "    print('\\nTest set: Average loss: {:.4f}, Accuracy: {}/{} ({:.0f}%)\\n'.format(\n",
        "        test_loss, correct, len(test_loader.dataset),\n",
        "        100. * correct / len(test_loader.dataset)))\n",
        "\n",
        "\n",
        "if __name__ == '__main__':\n",
        "    main()"
      ],
      "execution_count": 17,
      "outputs": [
        {
          "output_type": "stream",
          "text": [
            "Files already downloaded and verified\n",
            "Train Epoch: 1 [0/50000 (0%)]\tLoss: 2.768683\tLR: 0.01\n",
            "Train Epoch: 1 [4000/50000 (8%)]\tLoss: 2.310725\tLR: 0.01\n",
            "Train Epoch: 1 [8000/50000 (16%)]\tLoss: 2.410838\tLR: 0.01\n",
            "Train Epoch: 1 [12000/50000 (24%)]\tLoss: 2.218067\tLR: 0.01\n",
            "Train Epoch: 1 [16000/50000 (32%)]\tLoss: 2.441532\tLR: 0.01\n",
            "Train Epoch: 1 [20000/50000 (40%)]\tLoss: 2.163667\tLR: 0.01\n",
            "Train Epoch: 1 [24000/50000 (48%)]\tLoss: 2.212940\tLR: 0.01\n",
            "Train Epoch: 1 [28000/50000 (56%)]\tLoss: 1.899210\tLR: 0.01\n",
            "Train Epoch: 1 [32000/50000 (64%)]\tLoss: 2.166584\tLR: 0.01\n",
            "Train Epoch: 1 [36000/50000 (72%)]\tLoss: 2.130281\tLR: 0.01\n",
            "Train Epoch: 1 [40000/50000 (80%)]\tLoss: 2.174778\tLR: 0.01\n",
            "Train Epoch: 1 [44000/50000 (88%)]\tLoss: 2.293875\tLR: 0.01\n",
            "Train Epoch: 1 [48000/50000 (96%)]\tLoss: 1.944820\tLR: 0.01\n",
            "\n",
            "Test set: Average loss: 1.9549, Accuracy: 2546/10000 (25%)\n",
            "\n",
            "Train Epoch: 2 [0/50000 (0%)]\tLoss: 2.586738\tLR: 0.01\n",
            "Train Epoch: 2 [4000/50000 (8%)]\tLoss: 1.909199\tLR: 0.01\n",
            "Train Epoch: 2 [8000/50000 (16%)]\tLoss: 2.116374\tLR: 0.01\n",
            "Train Epoch: 2 [12000/50000 (24%)]\tLoss: 1.841112\tLR: 0.01\n",
            "Train Epoch: 2 [16000/50000 (32%)]\tLoss: 2.209199\tLR: 0.01\n",
            "Train Epoch: 2 [20000/50000 (40%)]\tLoss: 1.839383\tLR: 0.01\n",
            "Train Epoch: 2 [24000/50000 (48%)]\tLoss: 2.467499\tLR: 0.01\n",
            "Train Epoch: 2 [28000/50000 (56%)]\tLoss: 2.619030\tLR: 0.01\n",
            "Train Epoch: 2 [32000/50000 (64%)]\tLoss: 1.687422\tLR: 0.01\n",
            "Train Epoch: 2 [36000/50000 (72%)]\tLoss: 1.673631\tLR: 0.01\n",
            "Train Epoch: 2 [40000/50000 (80%)]\tLoss: 1.781601\tLR: 0.01\n",
            "Train Epoch: 2 [44000/50000 (88%)]\tLoss: 2.095440\tLR: 0.01\n",
            "Train Epoch: 2 [48000/50000 (96%)]\tLoss: 1.792115\tLR: 0.01\n",
            "\n",
            "Test set: Average loss: 1.6274, Accuracy: 3878/10000 (39%)\n",
            "\n",
            "Train Epoch: 3 [0/50000 (0%)]\tLoss: 1.800007\tLR: 0.01\n",
            "Train Epoch: 3 [4000/50000 (8%)]\tLoss: 1.663829\tLR: 0.01\n",
            "Train Epoch: 3 [8000/50000 (16%)]\tLoss: 1.582620\tLR: 0.01\n",
            "Train Epoch: 3 [12000/50000 (24%)]\tLoss: 2.650407\tLR: 0.01\n",
            "Train Epoch: 3 [16000/50000 (32%)]\tLoss: 1.446811\tLR: 0.01\n",
            "Train Epoch: 3 [20000/50000 (40%)]\tLoss: 1.952351\tLR: 0.01\n",
            "Train Epoch: 3 [24000/50000 (48%)]\tLoss: 1.255782\tLR: 0.01\n",
            "Train Epoch: 3 [28000/50000 (56%)]\tLoss: 1.337530\tLR: 0.01\n",
            "Train Epoch: 3 [32000/50000 (64%)]\tLoss: 1.458967\tLR: 0.01\n",
            "Train Epoch: 3 [36000/50000 (72%)]\tLoss: 1.164467\tLR: 0.01\n",
            "Train Epoch: 3 [40000/50000 (80%)]\tLoss: 1.224115\tLR: 0.01\n",
            "Train Epoch: 3 [44000/50000 (88%)]\tLoss: 1.494162\tLR: 0.01\n",
            "Train Epoch: 3 [48000/50000 (96%)]\tLoss: 1.185491\tLR: 0.01\n",
            "\n",
            "Test set: Average loss: 1.4364, Accuracy: 4631/10000 (46%)\n",
            "\n",
            "Train Epoch: 4 [0/50000 (0%)]\tLoss: 1.239586\tLR: 0.001\n",
            "Train Epoch: 4 [4000/50000 (8%)]\tLoss: 1.185432\tLR: 0.001\n",
            "Train Epoch: 4 [8000/50000 (16%)]\tLoss: 1.451748\tLR: 0.001\n",
            "Train Epoch: 4 [12000/50000 (24%)]\tLoss: 1.912564\tLR: 0.001\n",
            "Train Epoch: 4 [16000/50000 (32%)]\tLoss: 1.821549\tLR: 0.001\n",
            "Train Epoch: 4 [20000/50000 (40%)]\tLoss: 1.397722\tLR: 0.001\n",
            "Train Epoch: 4 [24000/50000 (48%)]\tLoss: 0.708915\tLR: 0.001\n",
            "Train Epoch: 4 [28000/50000 (56%)]\tLoss: 1.342795\tLR: 0.001\n",
            "Train Epoch: 4 [32000/50000 (64%)]\tLoss: 0.898163\tLR: 0.001\n",
            "Train Epoch: 4 [36000/50000 (72%)]\tLoss: 2.049521\tLR: 0.001\n",
            "Train Epoch: 4 [40000/50000 (80%)]\tLoss: 1.435813\tLR: 0.001\n",
            "Train Epoch: 4 [44000/50000 (88%)]\tLoss: 1.137008\tLR: 0.001\n",
            "Train Epoch: 4 [48000/50000 (96%)]\tLoss: 1.374325\tLR: 0.001\n",
            "\n",
            "Test set: Average loss: 1.2650, Accuracy: 5333/10000 (53%)\n",
            "\n",
            "Train Epoch: 5 [0/50000 (0%)]\tLoss: 1.139454\tLR: 0.001\n",
            "Train Epoch: 5 [4000/50000 (8%)]\tLoss: 0.883505\tLR: 0.001\n",
            "Train Epoch: 5 [8000/50000 (16%)]\tLoss: 1.070246\tLR: 0.001\n",
            "Train Epoch: 5 [12000/50000 (24%)]\tLoss: 1.261427\tLR: 0.001\n",
            "Train Epoch: 5 [16000/50000 (32%)]\tLoss: 1.188658\tLR: 0.001\n",
            "Train Epoch: 5 [20000/50000 (40%)]\tLoss: 1.214168\tLR: 0.001\n",
            "Train Epoch: 5 [24000/50000 (48%)]\tLoss: 1.591362\tLR: 0.001\n",
            "Train Epoch: 5 [28000/50000 (56%)]\tLoss: 0.965965\tLR: 0.001\n",
            "Train Epoch: 5 [32000/50000 (64%)]\tLoss: 0.972483\tLR: 0.001\n",
            "Train Epoch: 5 [36000/50000 (72%)]\tLoss: 1.824765\tLR: 0.001\n",
            "Train Epoch: 5 [40000/50000 (80%)]\tLoss: 1.376786\tLR: 0.001\n",
            "Train Epoch: 5 [44000/50000 (88%)]\tLoss: 1.526476\tLR: 0.001\n",
            "Train Epoch: 5 [48000/50000 (96%)]\tLoss: 0.987970\tLR: 0.001\n",
            "\n",
            "Test set: Average loss: 1.2002, Accuracy: 5694/10000 (57%)\n",
            "\n",
            "Train Epoch: 6 [0/50000 (0%)]\tLoss: 1.423431\tLR: 0.001\n",
            "Train Epoch: 6 [4000/50000 (8%)]\tLoss: 1.164825\tLR: 0.001\n",
            "Train Epoch: 6 [8000/50000 (16%)]\tLoss: 0.764325\tLR: 0.001\n",
            "Train Epoch: 6 [12000/50000 (24%)]\tLoss: 1.547139\tLR: 0.001\n",
            "Train Epoch: 6 [16000/50000 (32%)]\tLoss: 0.912239\tLR: 0.001\n",
            "Train Epoch: 6 [20000/50000 (40%)]\tLoss: 0.895287\tLR: 0.001\n",
            "Train Epoch: 6 [24000/50000 (48%)]\tLoss: 0.837726\tLR: 0.001\n",
            "Train Epoch: 6 [28000/50000 (56%)]\tLoss: 1.667379\tLR: 0.001\n",
            "Train Epoch: 6 [32000/50000 (64%)]\tLoss: 1.234073\tLR: 0.001\n",
            "Train Epoch: 6 [36000/50000 (72%)]\tLoss: 0.950285\tLR: 0.001\n",
            "Train Epoch: 6 [40000/50000 (80%)]\tLoss: 1.548336\tLR: 0.001\n",
            "Train Epoch: 6 [44000/50000 (88%)]\tLoss: 1.339875\tLR: 0.001\n",
            "Train Epoch: 6 [48000/50000 (96%)]\tLoss: 1.062781\tLR: 0.001\n",
            "\n",
            "Test set: Average loss: 1.1487, Accuracy: 5861/10000 (59%)\n",
            "\n",
            "Train Epoch: 7 [0/50000 (0%)]\tLoss: 1.161328\tLR: 0.0001\n",
            "Train Epoch: 7 [4000/50000 (8%)]\tLoss: 1.130795\tLR: 0.0001\n",
            "Train Epoch: 7 [8000/50000 (16%)]\tLoss: 1.789483\tLR: 0.0001\n",
            "Train Epoch: 7 [12000/50000 (24%)]\tLoss: 1.262417\tLR: 0.0001\n",
            "Train Epoch: 7 [16000/50000 (32%)]\tLoss: 0.963480\tLR: 0.0001\n",
            "Train Epoch: 7 [20000/50000 (40%)]\tLoss: 1.350099\tLR: 0.0001\n",
            "Train Epoch: 7 [24000/50000 (48%)]\tLoss: 0.930122\tLR: 0.0001\n",
            "Train Epoch: 7 [28000/50000 (56%)]\tLoss: 1.108182\tLR: 0.0001\n",
            "Train Epoch: 7 [32000/50000 (64%)]\tLoss: 1.766350\tLR: 0.0001\n",
            "Train Epoch: 7 [36000/50000 (72%)]\tLoss: 1.720872\tLR: 0.0001\n",
            "Train Epoch: 7 [40000/50000 (80%)]\tLoss: 0.583767\tLR: 0.0001\n",
            "Train Epoch: 7 [44000/50000 (88%)]\tLoss: 0.954530\tLR: 0.0001\n",
            "Train Epoch: 7 [48000/50000 (96%)]\tLoss: 1.082784\tLR: 0.0001\n",
            "\n",
            "Test set: Average loss: 1.1437, Accuracy: 5894/10000 (59%)\n",
            "\n",
            "Train Epoch: 8 [0/50000 (0%)]\tLoss: 1.157631\tLR: 0.0001\n",
            "Train Epoch: 8 [4000/50000 (8%)]\tLoss: 1.351900\tLR: 0.0001\n",
            "Train Epoch: 8 [8000/50000 (16%)]\tLoss: 0.720589\tLR: 0.0001\n",
            "Train Epoch: 8 [12000/50000 (24%)]\tLoss: 1.127400\tLR: 0.0001\n",
            "Train Epoch: 8 [16000/50000 (32%)]\tLoss: 0.956124\tLR: 0.0001\n",
            "Train Epoch: 8 [20000/50000 (40%)]\tLoss: 1.155332\tLR: 0.0001\n",
            "Train Epoch: 8 [24000/50000 (48%)]\tLoss: 0.592247\tLR: 0.0001\n",
            "Train Epoch: 8 [28000/50000 (56%)]\tLoss: 1.197272\tLR: 0.0001\n",
            "Train Epoch: 8 [32000/50000 (64%)]\tLoss: 1.083032\tLR: 0.0001\n",
            "Train Epoch: 8 [36000/50000 (72%)]\tLoss: 1.446824\tLR: 0.0001\n",
            "Train Epoch: 8 [40000/50000 (80%)]\tLoss: 0.503725\tLR: 0.0001\n",
            "Train Epoch: 8 [44000/50000 (88%)]\tLoss: 1.085113\tLR: 0.0001\n",
            "Train Epoch: 8 [48000/50000 (96%)]\tLoss: 1.351267\tLR: 0.0001\n",
            "\n",
            "Test set: Average loss: 1.1291, Accuracy: 5983/10000 (60%)\n",
            "\n",
            "Saved*\n"
          ],
          "name": "stdout"
        }
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "GoLWYqybJNN4",
        "colab_type": "text"
      },
      "source": [
        "### Transfer Learning\n",
        "\n",
        "[transfer learning code adapted from HERE](https://github.com/python-engineer/pytorchTutorial/blob/master/15_transfer_learning.py)"
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "n_BjB5Vdoaes",
        "colab_type": "code",
        "colab": {
          "base_uri": "https://localhost:8080/",
          "height": 1000
        },
        "outputId": "a28ac47b-8db0-415f-d6d5-30c13cf1fffb"
      },
      "source": [
        " def main():\n",
        "    epochs = 20\n",
        "    step_size = 3 # LR reduce\n",
        "    LR = 0.1 # 0.001\n",
        "    torch.manual_seed(42)\n",
        "    use_cuda = torch.cuda.is_available()\n",
        "    device = torch.device(\"cuda\" if use_cuda else \"cpu\")\n",
        "    print(device)\n",
        "    kwargs = {'batch_size': 8}\n",
        "    if use_cuda:\n",
        "        kwargs.update({'num_workers': 1,\n",
        "                       'pin_memory': True,\n",
        "                       'shuffle': True})\n",
        "\n",
        "    transform = transforms.Compose(\n",
        "        [transforms.ToTensor(),\n",
        "         transforms.Normalize((0.5, 0.5, 0.5), (0.5, 0.5, 0.5))])\n",
        "    dataset1 = datasets.CIFAR10('./data', train=True, download=True,\n",
        "                                transform=transform)\n",
        "    dataset2 = datasets.CIFAR10('./data', train=False,\n",
        "                                transform=transform)\n",
        "    train_loader = torch.utils.data.DataLoader(dataset1, **kwargs)\n",
        "    test_loader = torch.utils.data.DataLoader(dataset2, **kwargs)\n",
        "   \n",
        "   ###############################\n",
        "    model = torchvision.models.resnet18(pretrained=True)\n",
        "\n",
        "    #### ConvNet as fixed feature extractor ####\n",
        "    # Here, we need to freeze all the network except the final layer.\n",
        "    # We need to set requires_grad == False to freeze the parameters so that the gradients are not computed in backward()\n",
        "    # for param in model.parameters():\n",
        "    #     param.requires_grad = False\n",
        "\n",
        "    # instead of 2048 -> 2, its 2048 ->   since we have ten classes\n",
        "    model.fc = nn.Linear(model.fc.in_features, 10)\n",
        "    # model = ResNet50(img_channel=3, num_classes=10).to(device)\n",
        "\n",
        "    model = model.to(device)\n",
        "    ###############################\n",
        "\n",
        "\n",
        "    optimizer = optim.Adam(model.parameters(), lr=LR)\n",
        "    scheduler = optim.lr_scheduler.StepLR(optimizer, step_size=step_size, gamma=0.1)\n",
        "    \n",
        "    for epoch in range(1, epochs + 1):\n",
        "        train(model, device, train_loader, optimizer, epoch)\n",
        "        test(model, device, test_loader)\n",
        "        scheduler.step()\n",
        "\n",
        "def train(model, device, train_loader, optimizer, epoch):\n",
        "    model.train()\n",
        "    for batch_idx, (data, target) in enumerate(train_loader):\n",
        "        data, target = data.to(device), target.to(device)\n",
        "        output = model(data)\n",
        "\n",
        "        # loss = criterion(outputs, labels) # CrossEntropyLoss  combines nn.LogSoftmax() and nn.NLLLoss() in one single class\n",
        "        loss = F.nll_loss(F.log_softmax(output, 1), target)\n",
        "        # Backward and optimize\n",
        "        optimizer.zero_grad()\n",
        "        loss.backward()\n",
        "        optimizer.step()\n",
        "        \n",
        "        if batch_idx % 500 == 0:\n",
        "            print('Train Epoch: {} [{}/{} ({:.0f}%)]\\tLoss: {:.6f}\\tLR: {}'.format(\n",
        "                epoch, batch_idx * len(data), len(train_loader.dataset),\n",
        "                100. * batch_idx / len(train_loader), loss.item(), \n",
        "                optimizer.param_groups[0]['lr']))\n",
        "\n",
        "\n",
        "def test(model, device, test_loader):\n",
        "    model.eval()\n",
        "    test_loss = 0\n",
        "    correct = 0\n",
        "    with torch.no_grad():\n",
        "        for data, target in test_loader:\n",
        "            data, target = data.to(device), target.to(device)\n",
        "            output = model(data)\n",
        "            # sum up batch loss\n",
        "            test_loss += F.nll_loss(F.log_softmax(output, 1), target, reduction='sum').item()\n",
        "            # get the index of the max log-probability\n",
        "            pred = output.argmax(dim=1, keepdim=True)\n",
        "            correct += pred.eq(target.view_as(pred)).sum().item()\n",
        "\n",
        "    test_loss /= len(test_loader.dataset)\n",
        "    print('\\nTest set: Average loss: {:.4f}, Accuracy: {}/{} ({:.0f}%)\\n'.format(\n",
        "        test_loss, correct, len(test_loader.dataset),\n",
        "        100. * correct / len(test_loader.dataset)))\n",
        "\n",
        "\n",
        "if __name__ == '__main__':\n",
        "    main()"
      ],
      "execution_count": 16,
      "outputs": [
        {
          "output_type": "stream",
          "text": [
            "True\n",
            "Files already downloaded and verified\n",
            "Train Epoch: 1 [0/50000 (0%)]\tLoss: 2.603493\tLR: 0.1\n",
            "Train Epoch: 1 [4000/50000 (8%)]\tLoss: 2.257922\tLR: 0.1\n",
            "Train Epoch: 1 [8000/50000 (16%)]\tLoss: 1.923491\tLR: 0.1\n",
            "Train Epoch: 1 [12000/50000 (24%)]\tLoss: 1.795898\tLR: 0.1\n",
            "Train Epoch: 1 [16000/50000 (32%)]\tLoss: 1.944562\tLR: 0.1\n",
            "Train Epoch: 1 [20000/50000 (40%)]\tLoss: 2.219519\tLR: 0.1\n",
            "Train Epoch: 1 [24000/50000 (48%)]\tLoss: 1.729088\tLR: 0.1\n",
            "Train Epoch: 1 [28000/50000 (56%)]\tLoss: 2.610487\tLR: 0.1\n",
            "Train Epoch: 1 [32000/50000 (64%)]\tLoss: 1.921951\tLR: 0.1\n",
            "Train Epoch: 1 [36000/50000 (72%)]\tLoss: 2.006932\tLR: 0.1\n",
            "Train Epoch: 1 [40000/50000 (80%)]\tLoss: 1.936138\tLR: 0.1\n",
            "Train Epoch: 1 [44000/50000 (88%)]\tLoss: 2.252315\tLR: 0.1\n",
            "Train Epoch: 1 [48000/50000 (96%)]\tLoss: 1.885086\tLR: 0.1\n",
            "\n",
            "Test set: Average loss: 2.0193, Accuracy: 1835/10000 (18%)\n",
            "\n",
            "Train Epoch: 2 [0/50000 (0%)]\tLoss: 2.074857\tLR: 0.1\n",
            "Train Epoch: 2 [4000/50000 (8%)]\tLoss: 2.219013\tLR: 0.1\n",
            "Train Epoch: 2 [8000/50000 (16%)]\tLoss: 1.636225\tLR: 0.1\n",
            "Train Epoch: 2 [12000/50000 (24%)]\tLoss: 1.858338\tLR: 0.1\n",
            "Train Epoch: 2 [16000/50000 (32%)]\tLoss: 1.724954\tLR: 0.1\n",
            "Train Epoch: 2 [20000/50000 (40%)]\tLoss: 2.325874\tLR: 0.1\n",
            "Train Epoch: 2 [24000/50000 (48%)]\tLoss: 1.898384\tLR: 0.1\n",
            "Train Epoch: 2 [28000/50000 (56%)]\tLoss: 1.834069\tLR: 0.1\n",
            "Train Epoch: 2 [32000/50000 (64%)]\tLoss: 2.439600\tLR: 0.1\n",
            "Train Epoch: 2 [36000/50000 (72%)]\tLoss: 2.544346\tLR: 0.1\n",
            "Train Epoch: 2 [40000/50000 (80%)]\tLoss: 1.945888\tLR: 0.1\n",
            "Train Epoch: 2 [44000/50000 (88%)]\tLoss: 1.827154\tLR: 0.1\n",
            "Train Epoch: 2 [48000/50000 (96%)]\tLoss: 2.366677\tLR: 0.1\n",
            "\n",
            "Test set: Average loss: 1.9138, Accuracy: 1914/10000 (19%)\n",
            "\n",
            "Train Epoch: 3 [0/50000 (0%)]\tLoss: 2.978693\tLR: 0.1\n",
            "Train Epoch: 3 [4000/50000 (8%)]\tLoss: 2.266176\tLR: 0.1\n",
            "Train Epoch: 3 [8000/50000 (16%)]\tLoss: 1.955040\tLR: 0.1\n",
            "Train Epoch: 3 [12000/50000 (24%)]\tLoss: 2.071292\tLR: 0.1\n",
            "Train Epoch: 3 [16000/50000 (32%)]\tLoss: 1.726682\tLR: 0.1\n",
            "Train Epoch: 3 [20000/50000 (40%)]\tLoss: 1.759531\tLR: 0.1\n",
            "Train Epoch: 3 [24000/50000 (48%)]\tLoss: 1.909994\tLR: 0.1\n",
            "Train Epoch: 3 [28000/50000 (56%)]\tLoss: 1.594976\tLR: 0.1\n",
            "Train Epoch: 3 [32000/50000 (64%)]\tLoss: 2.023244\tLR: 0.1\n",
            "Train Epoch: 3 [36000/50000 (72%)]\tLoss: 1.806263\tLR: 0.1\n",
            "Train Epoch: 3 [40000/50000 (80%)]\tLoss: 1.822015\tLR: 0.1\n",
            "Train Epoch: 3 [44000/50000 (88%)]\tLoss: 1.917115\tLR: 0.1\n",
            "Train Epoch: 3 [48000/50000 (96%)]\tLoss: 2.101624\tLR: 0.1\n",
            "\n",
            "Test set: Average loss: 1.8662, Accuracy: 2058/10000 (21%)\n",
            "\n",
            "Train Epoch: 4 [0/50000 (0%)]\tLoss: 2.281416\tLR: 0.010000000000000002\n",
            "Train Epoch: 4 [4000/50000 (8%)]\tLoss: 2.189586\tLR: 0.010000000000000002\n",
            "Train Epoch: 4 [8000/50000 (16%)]\tLoss: 1.670610\tLR: 0.010000000000000002\n",
            "Train Epoch: 4 [12000/50000 (24%)]\tLoss: 1.741472\tLR: 0.010000000000000002\n",
            "Train Epoch: 4 [16000/50000 (32%)]\tLoss: 1.723989\tLR: 0.010000000000000002\n",
            "Train Epoch: 4 [20000/50000 (40%)]\tLoss: 1.594272\tLR: 0.010000000000000002\n",
            "Train Epoch: 4 [24000/50000 (48%)]\tLoss: 1.715666\tLR: 0.010000000000000002\n",
            "Train Epoch: 4 [28000/50000 (56%)]\tLoss: 1.802020\tLR: 0.010000000000000002\n",
            "Train Epoch: 4 [32000/50000 (64%)]\tLoss: 1.754653\tLR: 0.010000000000000002\n",
            "Train Epoch: 4 [36000/50000 (72%)]\tLoss: 1.950517\tLR: 0.010000000000000002\n",
            "Train Epoch: 4 [40000/50000 (80%)]\tLoss: 1.684902\tLR: 0.010000000000000002\n",
            "Train Epoch: 4 [44000/50000 (88%)]\tLoss: 2.486600\tLR: 0.010000000000000002\n",
            "Train Epoch: 4 [48000/50000 (96%)]\tLoss: 2.171191\tLR: 0.010000000000000002\n",
            "\n",
            "Test set: Average loss: 1.8179, Accuracy: 2421/10000 (24%)\n",
            "\n",
            "Train Epoch: 5 [0/50000 (0%)]\tLoss: 1.738111\tLR: 0.010000000000000002\n",
            "Train Epoch: 5 [4000/50000 (8%)]\tLoss: 1.815725\tLR: 0.010000000000000002\n",
            "Train Epoch: 5 [8000/50000 (16%)]\tLoss: 1.983553\tLR: 0.010000000000000002\n",
            "Train Epoch: 5 [12000/50000 (24%)]\tLoss: 1.813656\tLR: 0.010000000000000002\n",
            "Train Epoch: 5 [16000/50000 (32%)]\tLoss: 1.841983\tLR: 0.010000000000000002\n",
            "Train Epoch: 5 [20000/50000 (40%)]\tLoss: 1.757632\tLR: 0.010000000000000002\n",
            "Train Epoch: 5 [24000/50000 (48%)]\tLoss: 2.197808\tLR: 0.010000000000000002\n",
            "Train Epoch: 5 [28000/50000 (56%)]\tLoss: 1.675799\tLR: 0.010000000000000002\n",
            "Train Epoch: 5 [32000/50000 (64%)]\tLoss: 1.605536\tLR: 0.010000000000000002\n",
            "Train Epoch: 5 [36000/50000 (72%)]\tLoss: 2.728080\tLR: 0.010000000000000002\n",
            "Train Epoch: 5 [40000/50000 (80%)]\tLoss: 2.419058\tLR: 0.010000000000000002\n",
            "Train Epoch: 5 [44000/50000 (88%)]\tLoss: 1.621880\tLR: 0.010000000000000002\n",
            "Train Epoch: 5 [48000/50000 (96%)]\tLoss: 1.904451\tLR: 0.010000000000000002\n",
            "\n",
            "Test set: Average loss: 1.8192, Accuracy: 2251/10000 (23%)\n",
            "\n",
            "Train Epoch: 6 [0/50000 (0%)]\tLoss: 1.802706\tLR: 0.010000000000000002\n",
            "Train Epoch: 6 [4000/50000 (8%)]\tLoss: 1.595965\tLR: 0.010000000000000002\n",
            "Train Epoch: 6 [8000/50000 (16%)]\tLoss: 2.061661\tLR: 0.010000000000000002\n",
            "Train Epoch: 6 [12000/50000 (24%)]\tLoss: 1.735074\tLR: 0.010000000000000002\n",
            "Train Epoch: 6 [16000/50000 (32%)]\tLoss: 2.104781\tLR: 0.010000000000000002\n",
            "Train Epoch: 6 [20000/50000 (40%)]\tLoss: 1.688640\tLR: 0.010000000000000002\n",
            "Train Epoch: 6 [24000/50000 (48%)]\tLoss: 1.688105\tLR: 0.010000000000000002\n",
            "Train Epoch: 6 [28000/50000 (56%)]\tLoss: 1.734169\tLR: 0.010000000000000002\n",
            "Train Epoch: 6 [32000/50000 (64%)]\tLoss: 1.797154\tLR: 0.010000000000000002\n",
            "Train Epoch: 6 [36000/50000 (72%)]\tLoss: 1.562215\tLR: 0.010000000000000002\n",
            "Train Epoch: 6 [40000/50000 (80%)]\tLoss: 1.755164\tLR: 0.010000000000000002\n",
            "Train Epoch: 6 [44000/50000 (88%)]\tLoss: 1.919695\tLR: 0.010000000000000002\n",
            "Train Epoch: 6 [48000/50000 (96%)]\tLoss: 1.708703\tLR: 0.010000000000000002\n",
            "\n",
            "Test set: Average loss: 1.8506, Accuracy: 2373/10000 (24%)\n",
            "\n",
            "Train Epoch: 7 [0/50000 (0%)]\tLoss: 2.214963\tLR: 0.0010000000000000002\n"
          ],
          "name": "stdout"
        },
        {
          "output_type": "error",
          "ename": "KeyboardInterrupt",
          "evalue": "ignored",
          "traceback": [
            "\u001b[0;31m---------------------------------------------------------------------------\u001b[0m",
            "\u001b[0;31mKeyboardInterrupt\u001b[0m                         Traceback (most recent call last)",
            "\u001b[0;32m<ipython-input-16-17158fcdc59b>\u001b[0m in \u001b[0;36m<module>\u001b[0;34m()\u001b[0m\n\u001b[1;32m     89\u001b[0m \u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m     90\u001b[0m \u001b[0;32mif\u001b[0m \u001b[0m__name__\u001b[0m \u001b[0;34m==\u001b[0m \u001b[0;34m'__main__'\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m---> 91\u001b[0;31m    \u001b[0mmain\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m",
            "\u001b[0;32m<ipython-input-16-17158fcdc59b>\u001b[0m in \u001b[0;36mmain\u001b[0;34m()\u001b[0m\n\u001b[1;32m     44\u001b[0m \u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m     45\u001b[0m    \u001b[0;32mfor\u001b[0m \u001b[0mepoch\u001b[0m \u001b[0;32min\u001b[0m \u001b[0mrange\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0;36m1\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mepochs\u001b[0m \u001b[0;34m+\u001b[0m \u001b[0;36m1\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m---> 46\u001b[0;31m        \u001b[0mtrain\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mmodel\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mdevice\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mtrain_loader\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0moptimizer\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mepoch\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m\u001b[1;32m     47\u001b[0m        \u001b[0mtest\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mmodel\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mdevice\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mtest_loader\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m     48\u001b[0m        \u001b[0mscheduler\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mstep\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n",
            "\u001b[0;32m<ipython-input-16-17158fcdc59b>\u001b[0m in \u001b[0;36mtrain\u001b[0;34m(model, device, train_loader, optimizer, epoch)\u001b[0m\n\u001b[1;32m     52\u001b[0m    \u001b[0;32mfor\u001b[0m \u001b[0mbatch_idx\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0;34m(\u001b[0m\u001b[0mdata\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mtarget\u001b[0m\u001b[0;34m)\u001b[0m \u001b[0;32min\u001b[0m \u001b[0menumerate\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mtrain_loader\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m     53\u001b[0m        \u001b[0mdata\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mtarget\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0mdata\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mto\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mdevice\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mtarget\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mto\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mdevice\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m---> 54\u001b[0;31m        \u001b[0moutput\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0mmodel\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mdata\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m\u001b[1;32m     55\u001b[0m \u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m     56\u001b[0m        \u001b[0;31m# loss = criterion(outputs, labels) # CrossEntropyLoss  combines nn.LogSoftmax() and nn.NLLLoss() in one single class\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n",
            "\u001b[0;32m/usr/local/lib/python3.6/dist-packages/torch/nn/modules/module.py\u001b[0m in \u001b[0;36m__call__\u001b[0;34m(self, *input, **kwargs)\u001b[0m\n\u001b[1;32m    548\u001b[0m             \u001b[0mresult\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0mself\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0m_slow_forward\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0;34m*\u001b[0m\u001b[0minput\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0;34m**\u001b[0m\u001b[0mkwargs\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m    549\u001b[0m         \u001b[0;32melse\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m--> 550\u001b[0;31m             \u001b[0mresult\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0mself\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mforward\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0;34m*\u001b[0m\u001b[0minput\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0;34m**\u001b[0m\u001b[0mkwargs\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m\u001b[1;32m    551\u001b[0m         \u001b[0;32mfor\u001b[0m \u001b[0mhook\u001b[0m \u001b[0;32min\u001b[0m \u001b[0mself\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0m_forward_hooks\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mvalues\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m    552\u001b[0m             \u001b[0mhook_result\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0mhook\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mself\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0minput\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mresult\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n",
            "\u001b[0;32m/usr/local/lib/python3.6/dist-packages/torchvision/models/resnet.py\u001b[0m in \u001b[0;36mforward\u001b[0;34m(self, x)\u001b[0m\n\u001b[1;32m    218\u001b[0m \u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m    219\u001b[0m     \u001b[0;32mdef\u001b[0m \u001b[0mforward\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mself\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mx\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m--> 220\u001b[0;31m         \u001b[0;32mreturn\u001b[0m \u001b[0mself\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0m_forward_impl\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mx\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m\u001b[1;32m    221\u001b[0m \u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m    222\u001b[0m \u001b[0;34m\u001b[0m\u001b[0m\n",
            "\u001b[0;32m/usr/local/lib/python3.6/dist-packages/torchvision/models/resnet.py\u001b[0m in \u001b[0;36m_forward_impl\u001b[0;34m(self, x)\u001b[0m\n\u001b[1;32m    209\u001b[0m         \u001b[0mx\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0mself\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mlayer2\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mx\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m    210\u001b[0m         \u001b[0mx\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0mself\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mlayer3\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mx\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m--> 211\u001b[0;31m         \u001b[0mx\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0mself\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mlayer4\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mx\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m\u001b[1;32m    212\u001b[0m \u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m    213\u001b[0m         \u001b[0mx\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0mself\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mavgpool\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mx\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n",
            "\u001b[0;32m/usr/local/lib/python3.6/dist-packages/torch/nn/modules/module.py\u001b[0m in \u001b[0;36m__call__\u001b[0;34m(self, *input, **kwargs)\u001b[0m\n\u001b[1;32m    548\u001b[0m             \u001b[0mresult\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0mself\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0m_slow_forward\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0;34m*\u001b[0m\u001b[0minput\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0;34m**\u001b[0m\u001b[0mkwargs\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m    549\u001b[0m         \u001b[0;32melse\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m--> 550\u001b[0;31m             \u001b[0mresult\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0mself\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mforward\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0;34m*\u001b[0m\u001b[0minput\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0;34m**\u001b[0m\u001b[0mkwargs\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m\u001b[1;32m    551\u001b[0m         \u001b[0;32mfor\u001b[0m \u001b[0mhook\u001b[0m \u001b[0;32min\u001b[0m \u001b[0mself\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0m_forward_hooks\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mvalues\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m    552\u001b[0m             \u001b[0mhook_result\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0mhook\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mself\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0minput\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mresult\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n",
            "\u001b[0;32m/usr/local/lib/python3.6/dist-packages/torch/nn/modules/container.py\u001b[0m in \u001b[0;36mforward\u001b[0;34m(self, input)\u001b[0m\n\u001b[1;32m     98\u001b[0m     \u001b[0;32mdef\u001b[0m \u001b[0mforward\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mself\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0minput\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m     99\u001b[0m         \u001b[0;32mfor\u001b[0m \u001b[0mmodule\u001b[0m \u001b[0;32min\u001b[0m \u001b[0mself\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m--> 100\u001b[0;31m             \u001b[0minput\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0mmodule\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0minput\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m\u001b[1;32m    101\u001b[0m         \u001b[0;32mreturn\u001b[0m \u001b[0minput\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m    102\u001b[0m \u001b[0;34m\u001b[0m\u001b[0m\n",
            "\u001b[0;32m/usr/local/lib/python3.6/dist-packages/torch/nn/modules/module.py\u001b[0m in \u001b[0;36m__call__\u001b[0;34m(self, *input, **kwargs)\u001b[0m\n\u001b[1;32m    548\u001b[0m             \u001b[0mresult\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0mself\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0m_slow_forward\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0;34m*\u001b[0m\u001b[0minput\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0;34m**\u001b[0m\u001b[0mkwargs\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m    549\u001b[0m         \u001b[0;32melse\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m--> 550\u001b[0;31m             \u001b[0mresult\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0mself\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mforward\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0;34m*\u001b[0m\u001b[0minput\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0;34m**\u001b[0m\u001b[0mkwargs\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m\u001b[1;32m    551\u001b[0m         \u001b[0;32mfor\u001b[0m \u001b[0mhook\u001b[0m \u001b[0;32min\u001b[0m \u001b[0mself\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0m_forward_hooks\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mvalues\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m    552\u001b[0m             \u001b[0mhook_result\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0mhook\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mself\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0minput\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mresult\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n",
            "\u001b[0;32m/usr/local/lib/python3.6/dist-packages/torchvision/models/resnet.py\u001b[0m in \u001b[0;36mforward\u001b[0;34m(self, x)\u001b[0m\n\u001b[1;32m     62\u001b[0m \u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m     63\u001b[0m         \u001b[0mout\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0mself\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mconv2\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mout\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m---> 64\u001b[0;31m         \u001b[0mout\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0mself\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mbn2\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mout\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m\u001b[1;32m     65\u001b[0m \u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m     66\u001b[0m         \u001b[0;32mif\u001b[0m \u001b[0mself\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mdownsample\u001b[0m \u001b[0;32mis\u001b[0m \u001b[0;32mnot\u001b[0m \u001b[0;32mNone\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n",
            "\u001b[0;32m/usr/local/lib/python3.6/dist-packages/torch/nn/modules/module.py\u001b[0m in \u001b[0;36m__call__\u001b[0;34m(self, *input, **kwargs)\u001b[0m\n\u001b[1;32m    548\u001b[0m             \u001b[0mresult\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0mself\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0m_slow_forward\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0;34m*\u001b[0m\u001b[0minput\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0;34m**\u001b[0m\u001b[0mkwargs\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m    549\u001b[0m         \u001b[0;32melse\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m--> 550\u001b[0;31m             \u001b[0mresult\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0mself\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mforward\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0;34m*\u001b[0m\u001b[0minput\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0;34m**\u001b[0m\u001b[0mkwargs\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m\u001b[1;32m    551\u001b[0m         \u001b[0;32mfor\u001b[0m \u001b[0mhook\u001b[0m \u001b[0;32min\u001b[0m \u001b[0mself\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0m_forward_hooks\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mvalues\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m    552\u001b[0m             \u001b[0mhook_result\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0mhook\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mself\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0minput\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mresult\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n",
            "\u001b[0;32m/usr/local/lib/python3.6/dist-packages/torch/nn/modules/batchnorm.py\u001b[0m in \u001b[0;36mforward\u001b[0;34m(self, input)\u001b[0m\n\u001b[1;32m    104\u001b[0m             \u001b[0minput\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mself\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mrunning_mean\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mself\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mrunning_var\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mself\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mweight\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mself\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mbias\u001b[0m\u001b[0;34m,\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m    105\u001b[0m             \u001b[0mself\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mtraining\u001b[0m \u001b[0;32mor\u001b[0m \u001b[0;32mnot\u001b[0m \u001b[0mself\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mtrack_running_stats\u001b[0m\u001b[0;34m,\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m--> 106\u001b[0;31m             exponential_average_factor, self.eps)\n\u001b[0m\u001b[1;32m    107\u001b[0m \u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m    108\u001b[0m \u001b[0;34m\u001b[0m\u001b[0m\n",
            "\u001b[0;32m/usr/local/lib/python3.6/dist-packages/torch/nn/functional.py\u001b[0m in \u001b[0;36mbatch_norm\u001b[0;34m(input, running_mean, running_var, weight, bias, training, momentum, eps)\u001b[0m\n\u001b[1;32m   1921\u001b[0m     return torch.batch_norm(\n\u001b[1;32m   1922\u001b[0m         \u001b[0minput\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mweight\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mbias\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mrunning_mean\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mrunning_var\u001b[0m\u001b[0;34m,\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m-> 1923\u001b[0;31m         \u001b[0mtraining\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mmomentum\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0meps\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mtorch\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mbackends\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mcudnn\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0menabled\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m\u001b[1;32m   1924\u001b[0m     )\n\u001b[1;32m   1925\u001b[0m \u001b[0;34m\u001b[0m\u001b[0m\n",
            "\u001b[0;31mKeyboardInterrupt\u001b[0m: "
          ]
        }
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "6Lo1tcyWoahn",
        "colab_type": "code",
        "colab": {}
      },
      "source": [
        ""
      ],
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "PnO5vEdsvtuH",
        "colab_type": "text"
      },
      "source": [
        "# VAE"
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "fQ1v_KYovhdJ",
        "colab_type": "code",
        "colab": {}
      },
      "source": [
        "# import numpy as np\n",
        "# import pandas as pd\n",
        "# from sklearn.kernel_approximation import RBFSampler\n",
        "# from sklearn.linear_model import SGDClassifier\n",
        "# from sklearn.model_selection import train_test_split\n",
        "# from sklearn import svm\n",
        "# from sklearn.metrics import classification_report, confusion_matrix\n",
        "# from sklearn import metrics\n",
        "# from sklearn.linear_model import LogisticRegression\n",
        "# from sklearn.naive_bayes import GaussianNB\n",
        "# from sklearn.neighbors import KNeighborsClassifier\n",
        "# from sklearn.tree import DecisionTreeClassifier\n",
        "# from sklearn.metrics import (precision_score, recall_score,f1_score, accuracy_score,mean_squared_error,mean_absolute_error)\n",
        "# from sklearn.ensemble import AdaBoostClassifier\n",
        "# from sklearn.ensemble import RandomForestClassifier\n",
        "# from sklearn.preprocessing import Normalizer\n",
        "\n",
        "# traindata = pd.read_csv('https://raw.githubusercontent.com/vinayakumarr/mlc18/master/IDS/data/KDDTrain.csv', header=None)\n",
        "# testdata = pd.read_csv('https://raw.githubusercontent.com/vinayakumarr/mlc18/master/IDS/data/KDDTest.csv', header=None)\n",
        "# testdata.head(3)"
      ],
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "uV-odpRBJL_P",
        "colab_type": "code",
        "colab": {}
      },
      "source": [
        ""
      ],
      "execution_count": null,
      "outputs": []
    }
  ]
}