{
  "nbformat": 4,
  "nbformat_minor": 0,
  "metadata": {
    "colab": {
      "name": " Boston housing - recommendation system",
      "provenance": [],
      "collapsed_sections": []
    },
    "kernelspec": {
      "name": "python3",
      "display_name": "Python 3"
    }
  },
  "cells": [
    {
      "cell_type": "code",
      "metadata": {
        "id": "SvR5cAjoaGAW",
        "colab_type": "code",
        "colab": {}
      },
      "source": [
        "import numpy as np\n",
        "import pandas as pd\n",
        "\n",
        "from sklearn.ensemble import RandomForestClassifier,AdaBoostClassifier,GradientBoostingClassifier,VotingClassifier\n",
        "\n",
        "from sklearn.tree import DecisionTreeClassifier\n",
        "from sklearn.model_selection import cross_val_score\n",
        "from sklearn.linear_model import LogisticRegression\n",
        "from sklearn.naive_bayes import *\n",
        "from sklearn.neighbors import KNeighborsClassifier\n",
        "from sklearn.svm import LinearSVC,OneClassSVM\n",
        "\n",
        "from sklearn.model_selection import train_test_split\n",
        "from sklearn import metrics\n",
        "\n",
        "from sklearn.datasets import load_boston\n",
        "\n",
        "boston = load_boston()\n",
        "import matplotlib.pyplot as plt\n",
        "\n",
        "%matplotlib inline"
      ],
      "execution_count": 0,
      "outputs": []
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "99lvbvHa-9L4",
        "colab_type": "text"
      },
      "source": [
        "## Loading data and pre-processing \n"
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "5iCwdmaoaO5n",
        "colab_type": "code",
        "colab": {
          "base_uri": "https://localhost:8080/",
          "height": 204
        },
        "outputId": "9b4bdd35-9898-4ef5-da0b-81309af829a3"
      },
      "source": [
        "df_boston = pd.DataFrame(boston.data,columns=boston.feature_names)\n",
        "df_boston['target'] = pd.Series(boston.target)\n",
        "df = df_boston\n",
        "df.head()"
      ],
      "execution_count": 7,
      "outputs": [
        {
          "output_type": "execute_result",
          "data": {
            "text/html": [
              "<div>\n",
              "<style scoped>\n",
              "    .dataframe tbody tr th:only-of-type {\n",
              "        vertical-align: middle;\n",
              "    }\n",
              "\n",
              "    .dataframe tbody tr th {\n",
              "        vertical-align: top;\n",
              "    }\n",
              "\n",
              "    .dataframe thead th {\n",
              "        text-align: right;\n",
              "    }\n",
              "</style>\n",
              "<table border=\"1\" class=\"dataframe\">\n",
              "  <thead>\n",
              "    <tr style=\"text-align: right;\">\n",
              "      <th></th>\n",
              "      <th>CRIM</th>\n",
              "      <th>ZN</th>\n",
              "      <th>INDUS</th>\n",
              "      <th>CHAS</th>\n",
              "      <th>NOX</th>\n",
              "      <th>RM</th>\n",
              "      <th>AGE</th>\n",
              "      <th>DIS</th>\n",
              "      <th>RAD</th>\n",
              "      <th>TAX</th>\n",
              "      <th>PTRATIO</th>\n",
              "      <th>B</th>\n",
              "      <th>LSTAT</th>\n",
              "      <th>target</th>\n",
              "    </tr>\n",
              "  </thead>\n",
              "  <tbody>\n",
              "    <tr>\n",
              "      <th>0</th>\n",
              "      <td>0.00632</td>\n",
              "      <td>18.0</td>\n",
              "      <td>2.31</td>\n",
              "      <td>0.0</td>\n",
              "      <td>0.538</td>\n",
              "      <td>6.575</td>\n",
              "      <td>65.2</td>\n",
              "      <td>4.0900</td>\n",
              "      <td>1.0</td>\n",
              "      <td>296.0</td>\n",
              "      <td>15.3</td>\n",
              "      <td>396.90</td>\n",
              "      <td>4.98</td>\n",
              "      <td>24.0</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <th>1</th>\n",
              "      <td>0.02731</td>\n",
              "      <td>0.0</td>\n",
              "      <td>7.07</td>\n",
              "      <td>0.0</td>\n",
              "      <td>0.469</td>\n",
              "      <td>6.421</td>\n",
              "      <td>78.9</td>\n",
              "      <td>4.9671</td>\n",
              "      <td>2.0</td>\n",
              "      <td>242.0</td>\n",
              "      <td>17.8</td>\n",
              "      <td>396.90</td>\n",
              "      <td>9.14</td>\n",
              "      <td>21.6</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <th>2</th>\n",
              "      <td>0.02729</td>\n",
              "      <td>0.0</td>\n",
              "      <td>7.07</td>\n",
              "      <td>0.0</td>\n",
              "      <td>0.469</td>\n",
              "      <td>7.185</td>\n",
              "      <td>61.1</td>\n",
              "      <td>4.9671</td>\n",
              "      <td>2.0</td>\n",
              "      <td>242.0</td>\n",
              "      <td>17.8</td>\n",
              "      <td>392.83</td>\n",
              "      <td>4.03</td>\n",
              "      <td>34.7</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <th>3</th>\n",
              "      <td>0.03237</td>\n",
              "      <td>0.0</td>\n",
              "      <td>2.18</td>\n",
              "      <td>0.0</td>\n",
              "      <td>0.458</td>\n",
              "      <td>6.998</td>\n",
              "      <td>45.8</td>\n",
              "      <td>6.0622</td>\n",
              "      <td>3.0</td>\n",
              "      <td>222.0</td>\n",
              "      <td>18.7</td>\n",
              "      <td>394.63</td>\n",
              "      <td>2.94</td>\n",
              "      <td>33.4</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <th>4</th>\n",
              "      <td>0.06905</td>\n",
              "      <td>0.0</td>\n",
              "      <td>2.18</td>\n",
              "      <td>0.0</td>\n",
              "      <td>0.458</td>\n",
              "      <td>7.147</td>\n",
              "      <td>54.2</td>\n",
              "      <td>6.0622</td>\n",
              "      <td>3.0</td>\n",
              "      <td>222.0</td>\n",
              "      <td>18.7</td>\n",
              "      <td>396.90</td>\n",
              "      <td>5.33</td>\n",
              "      <td>36.2</td>\n",
              "    </tr>\n",
              "  </tbody>\n",
              "</table>\n",
              "</div>"
            ],
            "text/plain": [
              "      CRIM    ZN  INDUS  CHAS    NOX  ...    TAX  PTRATIO       B  LSTAT  target\n",
              "0  0.00632  18.0   2.31   0.0  0.538  ...  296.0     15.3  396.90   4.98    24.0\n",
              "1  0.02731   0.0   7.07   0.0  0.469  ...  242.0     17.8  396.90   9.14    21.6\n",
              "2  0.02729   0.0   7.07   0.0  0.469  ...  242.0     17.8  392.83   4.03    34.7\n",
              "3  0.03237   0.0   2.18   0.0  0.458  ...  222.0     18.7  394.63   2.94    33.4\n",
              "4  0.06905   0.0   2.18   0.0  0.458  ...  222.0     18.7  396.90   5.33    36.2\n",
              "\n",
              "[5 rows x 14 columns]"
            ]
          },
          "metadata": {
            "tags": []
          },
          "execution_count": 7
        }
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "olt8EIPbbSZM",
        "colab_type": "text"
      },
      "source": [
        "| Feature | Description                                                           |\n",
        "|---------|-----------------------------------------------------------------------|\n",
        "| crim    | per capita crime rate by town.                                        |\n",
        "| zn      | proportion of residential land zoned for lots over 25,000     |\n",
        "|         |                                                                       |\n",
        "| indus   | proportion of non-retail business acres per town.                     |\n",
        "| chas    | Charles River dummy variable (= 1 if tract bounds river; 0otherwise|\n",
        "|         |                                                                       |\n",
        "| nox     | nitrogen oxides concentration (parts per 10 million).                 |\n",
        "| lstat   | median value of owner-occupied homes in $$ 1000s.                       |\n",
        "| rm      | average number of rooms per dwelling.                                 |\n",
        "| age     | proportion of owner-occupied units built prior to 1940.               |\n",
        "| dis     | weighted mean of distances to five Boston employment centres.         |\n",
        "| rad     | index of accessibility to radial highways.                            |\n",
        "| tax     | full-value property-tax rate per \\$10,000.                             |\n",
        "| ptratio | pupil-teacher ratio by town.                                          |\n",
        "| black   | 1000(Bk - 0.63)^2 where Bk is the proportion of blacks by town.       |\n",
        "| lstat   | lower   status of the population (percent).                           |\n",
        "| medv    | median   value of owner-occupied homes in $1000s.                     |"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "l7ZhKFJYg7Hk",
        "colab_type": "text"
      },
      "source": [
        "###  surely no one cares about nox,chas "
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "yzRPXOs5aO9O",
        "colab_type": "code",
        "colab": {
          "base_uri": "https://localhost:8080/",
          "height": 979
        },
        "outputId": "7aaad9d4-0a67-42dd-9dfe-6c336d5c1585"
      },
      "source": [
        "df =df_boston.drop(['NOX','CHAS','INDUS','DIS','RAD'],axis=1)\n",
        "df_byCRIM = df.sort_values('CRIM')\n",
        "\n",
        "own = np.zeros(len(df_byCRIM))\n",
        "own[:20] = 1 \n",
        "df_byCRIM['own'] = own\n",
        "\n",
        "df = df_byCRIM.sort_index()\n",
        "df_byCRIM.head(30)"
      ],
      "execution_count": 36,
      "outputs": [
        {
          "output_type": "execute_result",
          "data": {
            "text/html": [
              "<div>\n",
              "<style scoped>\n",
              "    .dataframe tbody tr th:only-of-type {\n",
              "        vertical-align: middle;\n",
              "    }\n",
              "\n",
              "    .dataframe tbody tr th {\n",
              "        vertical-align: top;\n",
              "    }\n",
              "\n",
              "    .dataframe thead th {\n",
              "        text-align: right;\n",
              "    }\n",
              "</style>\n",
              "<table border=\"1\" class=\"dataframe\">\n",
              "  <thead>\n",
              "    <tr style=\"text-align: right;\">\n",
              "      <th></th>\n",
              "      <th>CRIM</th>\n",
              "      <th>ZN</th>\n",
              "      <th>RM</th>\n",
              "      <th>AGE</th>\n",
              "      <th>TAX</th>\n",
              "      <th>PTRATIO</th>\n",
              "      <th>B</th>\n",
              "      <th>LSTAT</th>\n",
              "      <th>target</th>\n",
              "      <th>own</th>\n",
              "    </tr>\n",
              "  </thead>\n",
              "  <tbody>\n",
              "    <tr>\n",
              "      <th>0</th>\n",
              "      <td>0.00632</td>\n",
              "      <td>18.0</td>\n",
              "      <td>6.575</td>\n",
              "      <td>65.2</td>\n",
              "      <td>296.0</td>\n",
              "      <td>15.3</td>\n",
              "      <td>396.90</td>\n",
              "      <td>4.98</td>\n",
              "      <td>24.0</td>\n",
              "      <td>1.0</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <th>284</th>\n",
              "      <td>0.00906</td>\n",
              "      <td>90.0</td>\n",
              "      <td>7.088</td>\n",
              "      <td>20.8</td>\n",
              "      <td>285.0</td>\n",
              "      <td>15.3</td>\n",
              "      <td>394.72</td>\n",
              "      <td>7.85</td>\n",
              "      <td>32.2</td>\n",
              "      <td>1.0</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <th>285</th>\n",
              "      <td>0.01096</td>\n",
              "      <td>55.0</td>\n",
              "      <td>6.453</td>\n",
              "      <td>31.9</td>\n",
              "      <td>300.0</td>\n",
              "      <td>15.3</td>\n",
              "      <td>394.72</td>\n",
              "      <td>8.23</td>\n",
              "      <td>22.0</td>\n",
              "      <td>1.0</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <th>341</th>\n",
              "      <td>0.01301</td>\n",
              "      <td>35.0</td>\n",
              "      <td>7.241</td>\n",
              "      <td>49.3</td>\n",
              "      <td>284.0</td>\n",
              "      <td>15.5</td>\n",
              "      <td>394.74</td>\n",
              "      <td>5.49</td>\n",
              "      <td>32.7</td>\n",
              "      <td>1.0</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <th>55</th>\n",
              "      <td>0.01311</td>\n",
              "      <td>90.0</td>\n",
              "      <td>7.249</td>\n",
              "      <td>21.9</td>\n",
              "      <td>226.0</td>\n",
              "      <td>17.9</td>\n",
              "      <td>395.93</td>\n",
              "      <td>4.81</td>\n",
              "      <td>35.4</td>\n",
              "      <td>1.0</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <th>54</th>\n",
              "      <td>0.01360</td>\n",
              "      <td>75.0</td>\n",
              "      <td>5.888</td>\n",
              "      <td>47.6</td>\n",
              "      <td>469.0</td>\n",
              "      <td>21.1</td>\n",
              "      <td>396.90</td>\n",
              "      <td>14.80</td>\n",
              "      <td>18.9</td>\n",
              "      <td>1.0</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <th>195</th>\n",
              "      <td>0.01381</td>\n",
              "      <td>80.0</td>\n",
              "      <td>7.875</td>\n",
              "      <td>32.0</td>\n",
              "      <td>255.0</td>\n",
              "      <td>14.4</td>\n",
              "      <td>394.23</td>\n",
              "      <td>2.97</td>\n",
              "      <td>50.0</td>\n",
              "      <td>1.0</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <th>57</th>\n",
              "      <td>0.01432</td>\n",
              "      <td>100.0</td>\n",
              "      <td>6.816</td>\n",
              "      <td>40.5</td>\n",
              "      <td>256.0</td>\n",
              "      <td>15.1</td>\n",
              "      <td>392.90</td>\n",
              "      <td>3.95</td>\n",
              "      <td>31.6</td>\n",
              "      <td>1.0</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <th>194</th>\n",
              "      <td>0.01439</td>\n",
              "      <td>60.0</td>\n",
              "      <td>6.604</td>\n",
              "      <td>18.8</td>\n",
              "      <td>265.0</td>\n",
              "      <td>15.6</td>\n",
              "      <td>376.70</td>\n",
              "      <td>4.38</td>\n",
              "      <td>29.1</td>\n",
              "      <td>1.0</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <th>348</th>\n",
              "      <td>0.01501</td>\n",
              "      <td>80.0</td>\n",
              "      <td>6.635</td>\n",
              "      <td>29.7</td>\n",
              "      <td>280.0</td>\n",
              "      <td>17.0</td>\n",
              "      <td>390.94</td>\n",
              "      <td>5.99</td>\n",
              "      <td>24.5</td>\n",
              "      <td>1.0</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <th>283</th>\n",
              "      <td>0.01501</td>\n",
              "      <td>90.0</td>\n",
              "      <td>7.923</td>\n",
              "      <td>24.8</td>\n",
              "      <td>198.0</td>\n",
              "      <td>13.6</td>\n",
              "      <td>395.52</td>\n",
              "      <td>3.16</td>\n",
              "      <td>50.0</td>\n",
              "      <td>1.0</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <th>256</th>\n",
              "      <td>0.01538</td>\n",
              "      <td>90.0</td>\n",
              "      <td>7.454</td>\n",
              "      <td>34.2</td>\n",
              "      <td>244.0</td>\n",
              "      <td>15.9</td>\n",
              "      <td>386.34</td>\n",
              "      <td>3.11</td>\n",
              "      <td>44.0</td>\n",
              "      <td>1.0</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <th>353</th>\n",
              "      <td>0.01709</td>\n",
              "      <td>90.0</td>\n",
              "      <td>6.728</td>\n",
              "      <td>36.1</td>\n",
              "      <td>187.0</td>\n",
              "      <td>17.0</td>\n",
              "      <td>384.46</td>\n",
              "      <td>4.50</td>\n",
              "      <td>30.1</td>\n",
              "      <td>1.0</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <th>200</th>\n",
              "      <td>0.01778</td>\n",
              "      <td>95.0</td>\n",
              "      <td>7.135</td>\n",
              "      <td>13.9</td>\n",
              "      <td>402.0</td>\n",
              "      <td>17.0</td>\n",
              "      <td>384.30</td>\n",
              "      <td>4.45</td>\n",
              "      <td>32.9</td>\n",
              "      <td>1.0</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <th>347</th>\n",
              "      <td>0.01870</td>\n",
              "      <td>85.0</td>\n",
              "      <td>6.516</td>\n",
              "      <td>27.7</td>\n",
              "      <td>351.0</td>\n",
              "      <td>17.9</td>\n",
              "      <td>392.43</td>\n",
              "      <td>6.36</td>\n",
              "      <td>23.1</td>\n",
              "      <td>1.0</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <th>64</th>\n",
              "      <td>0.01951</td>\n",
              "      <td>17.5</td>\n",
              "      <td>7.104</td>\n",
              "      <td>59.5</td>\n",
              "      <td>216.0</td>\n",
              "      <td>18.6</td>\n",
              "      <td>393.24</td>\n",
              "      <td>8.05</td>\n",
              "      <td>33.0</td>\n",
              "      <td>1.0</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <th>286</th>\n",
              "      <td>0.01965</td>\n",
              "      <td>80.0</td>\n",
              "      <td>6.230</td>\n",
              "      <td>31.5</td>\n",
              "      <td>241.0</td>\n",
              "      <td>18.2</td>\n",
              "      <td>341.60</td>\n",
              "      <td>12.93</td>\n",
              "      <td>20.1</td>\n",
              "      <td>1.0</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <th>204</th>\n",
              "      <td>0.02009</td>\n",
              "      <td>95.0</td>\n",
              "      <td>8.034</td>\n",
              "      <td>31.9</td>\n",
              "      <td>224.0</td>\n",
              "      <td>14.7</td>\n",
              "      <td>390.55</td>\n",
              "      <td>2.88</td>\n",
              "      <td>50.0</td>\n",
              "      <td>1.0</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <th>56</th>\n",
              "      <td>0.02055</td>\n",
              "      <td>85.0</td>\n",
              "      <td>6.383</td>\n",
              "      <td>35.7</td>\n",
              "      <td>313.0</td>\n",
              "      <td>17.3</td>\n",
              "      <td>396.90</td>\n",
              "      <td>5.77</td>\n",
              "      <td>24.7</td>\n",
              "      <td>1.0</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <th>202</th>\n",
              "      <td>0.02177</td>\n",
              "      <td>82.5</td>\n",
              "      <td>7.610</td>\n",
              "      <td>15.7</td>\n",
              "      <td>348.0</td>\n",
              "      <td>14.7</td>\n",
              "      <td>395.38</td>\n",
              "      <td>3.11</td>\n",
              "      <td>42.3</td>\n",
              "      <td>1.0</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <th>193</th>\n",
              "      <td>0.02187</td>\n",
              "      <td>60.0</td>\n",
              "      <td>6.800</td>\n",
              "      <td>9.9</td>\n",
              "      <td>265.0</td>\n",
              "      <td>15.6</td>\n",
              "      <td>393.37</td>\n",
              "      <td>5.03</td>\n",
              "      <td>31.1</td>\n",
              "      <td>0.0</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <th>342</th>\n",
              "      <td>0.02498</td>\n",
              "      <td>0.0</td>\n",
              "      <td>6.540</td>\n",
              "      <td>59.7</td>\n",
              "      <td>422.0</td>\n",
              "      <td>15.9</td>\n",
              "      <td>389.96</td>\n",
              "      <td>8.65</td>\n",
              "      <td>16.5</td>\n",
              "      <td>0.0</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <th>343</th>\n",
              "      <td>0.02543</td>\n",
              "      <td>55.0</td>\n",
              "      <td>6.696</td>\n",
              "      <td>56.4</td>\n",
              "      <td>370.0</td>\n",
              "      <td>17.6</td>\n",
              "      <td>396.90</td>\n",
              "      <td>7.18</td>\n",
              "      <td>23.9</td>\n",
              "      <td>0.0</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <th>2</th>\n",
              "      <td>0.02729</td>\n",
              "      <td>0.0</td>\n",
              "      <td>7.185</td>\n",
              "      <td>61.1</td>\n",
              "      <td>242.0</td>\n",
              "      <td>17.8</td>\n",
              "      <td>392.83</td>\n",
              "      <td>4.03</td>\n",
              "      <td>34.7</td>\n",
              "      <td>0.0</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <th>1</th>\n",
              "      <td>0.02731</td>\n",
              "      <td>0.0</td>\n",
              "      <td>6.421</td>\n",
              "      <td>78.9</td>\n",
              "      <td>242.0</td>\n",
              "      <td>17.8</td>\n",
              "      <td>396.90</td>\n",
              "      <td>9.14</td>\n",
              "      <td>21.6</td>\n",
              "      <td>0.0</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <th>39</th>\n",
              "      <td>0.02763</td>\n",
              "      <td>75.0</td>\n",
              "      <td>6.595</td>\n",
              "      <td>21.8</td>\n",
              "      <td>252.0</td>\n",
              "      <td>18.3</td>\n",
              "      <td>395.63</td>\n",
              "      <td>4.32</td>\n",
              "      <td>30.8</td>\n",
              "      <td>0.0</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <th>93</th>\n",
              "      <td>0.02875</td>\n",
              "      <td>28.0</td>\n",
              "      <td>6.211</td>\n",
              "      <td>28.9</td>\n",
              "      <td>270.0</td>\n",
              "      <td>18.2</td>\n",
              "      <td>396.33</td>\n",
              "      <td>6.21</td>\n",
              "      <td>25.0</td>\n",
              "      <td>0.0</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <th>349</th>\n",
              "      <td>0.02899</td>\n",
              "      <td>40.0</td>\n",
              "      <td>6.939</td>\n",
              "      <td>34.5</td>\n",
              "      <td>335.0</td>\n",
              "      <td>19.7</td>\n",
              "      <td>389.85</td>\n",
              "      <td>5.89</td>\n",
              "      <td>26.6</td>\n",
              "      <td>0.0</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <th>5</th>\n",
              "      <td>0.02985</td>\n",
              "      <td>0.0</td>\n",
              "      <td>6.430</td>\n",
              "      <td>58.7</td>\n",
              "      <td>222.0</td>\n",
              "      <td>18.7</td>\n",
              "      <td>394.12</td>\n",
              "      <td>5.21</td>\n",
              "      <td>28.7</td>\n",
              "      <td>0.0</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <th>337</th>\n",
              "      <td>0.03041</td>\n",
              "      <td>0.0</td>\n",
              "      <td>5.895</td>\n",
              "      <td>59.6</td>\n",
              "      <td>224.0</td>\n",
              "      <td>20.2</td>\n",
              "      <td>394.81</td>\n",
              "      <td>10.56</td>\n",
              "      <td>18.5</td>\n",
              "      <td>0.0</td>\n",
              "    </tr>\n",
              "  </tbody>\n",
              "</table>\n",
              "</div>"
            ],
            "text/plain": [
              "        CRIM     ZN     RM   AGE    TAX  PTRATIO       B  LSTAT  target  own\n",
              "0    0.00632   18.0  6.575  65.2  296.0     15.3  396.90   4.98    24.0  1.0\n",
              "284  0.00906   90.0  7.088  20.8  285.0     15.3  394.72   7.85    32.2  1.0\n",
              "285  0.01096   55.0  6.453  31.9  300.0     15.3  394.72   8.23    22.0  1.0\n",
              "341  0.01301   35.0  7.241  49.3  284.0     15.5  394.74   5.49    32.7  1.0\n",
              "55   0.01311   90.0  7.249  21.9  226.0     17.9  395.93   4.81    35.4  1.0\n",
              "54   0.01360   75.0  5.888  47.6  469.0     21.1  396.90  14.80    18.9  1.0\n",
              "195  0.01381   80.0  7.875  32.0  255.0     14.4  394.23   2.97    50.0  1.0\n",
              "57   0.01432  100.0  6.816  40.5  256.0     15.1  392.90   3.95    31.6  1.0\n",
              "194  0.01439   60.0  6.604  18.8  265.0     15.6  376.70   4.38    29.1  1.0\n",
              "348  0.01501   80.0  6.635  29.7  280.0     17.0  390.94   5.99    24.5  1.0\n",
              "283  0.01501   90.0  7.923  24.8  198.0     13.6  395.52   3.16    50.0  1.0\n",
              "256  0.01538   90.0  7.454  34.2  244.0     15.9  386.34   3.11    44.0  1.0\n",
              "353  0.01709   90.0  6.728  36.1  187.0     17.0  384.46   4.50    30.1  1.0\n",
              "200  0.01778   95.0  7.135  13.9  402.0     17.0  384.30   4.45    32.9  1.0\n",
              "347  0.01870   85.0  6.516  27.7  351.0     17.9  392.43   6.36    23.1  1.0\n",
              "64   0.01951   17.5  7.104  59.5  216.0     18.6  393.24   8.05    33.0  1.0\n",
              "286  0.01965   80.0  6.230  31.5  241.0     18.2  341.60  12.93    20.1  1.0\n",
              "204  0.02009   95.0  8.034  31.9  224.0     14.7  390.55   2.88    50.0  1.0\n",
              "56   0.02055   85.0  6.383  35.7  313.0     17.3  396.90   5.77    24.7  1.0\n",
              "202  0.02177   82.5  7.610  15.7  348.0     14.7  395.38   3.11    42.3  1.0\n",
              "193  0.02187   60.0  6.800   9.9  265.0     15.6  393.37   5.03    31.1  0.0\n",
              "342  0.02498    0.0  6.540  59.7  422.0     15.9  389.96   8.65    16.5  0.0\n",
              "343  0.02543   55.0  6.696  56.4  370.0     17.6  396.90   7.18    23.9  0.0\n",
              "2    0.02729    0.0  7.185  61.1  242.0     17.8  392.83   4.03    34.7  0.0\n",
              "1    0.02731    0.0  6.421  78.9  242.0     17.8  396.90   9.14    21.6  0.0\n",
              "39   0.02763   75.0  6.595  21.8  252.0     18.3  395.63   4.32    30.8  0.0\n",
              "93   0.02875   28.0  6.211  28.9  270.0     18.2  396.33   6.21    25.0  0.0\n",
              "349  0.02899   40.0  6.939  34.5  335.0     19.7  389.85   5.89    26.6  0.0\n",
              "5    0.02985    0.0  6.430  58.7  222.0     18.7  394.12   5.21    28.7  0.0\n",
              "337  0.03041    0.0  5.895  59.6  224.0     20.2  394.81  10.56    18.5  0.0"
            ]
          },
          "metadata": {
            "tags": []
          },
          "execution_count": 36
        }
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "wS6gSoTuaPAO",
        "colab_type": "code",
        "colab": {}
      },
      "source": [
        "if len(df_byCRIM) > 10:\n",
        "   df_client = df_byCRIM[:10]\n",
        "   df_listings = df_byCRIM[10:]"
      ],
      "execution_count": 0,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "6Rz0CP0pdVSH",
        "colab_type": "code",
        "colab": {
          "base_uri": "https://localhost:8080/",
          "height": 483
        },
        "outputId": "7b27921c-7b10-4b1e-9aea-34a278f0e03d"
      },
      "source": [
        "df_new = pd.concat([df_client, df] ,axis=0)\n",
        "df_new.head(14)"
      ],
      "execution_count": 10,
      "outputs": [
        {
          "output_type": "execute_result",
          "data": {
            "text/html": [
              "<div>\n",
              "<style scoped>\n",
              "    .dataframe tbody tr th:only-of-type {\n",
              "        vertical-align: middle;\n",
              "    }\n",
              "\n",
              "    .dataframe tbody tr th {\n",
              "        vertical-align: top;\n",
              "    }\n",
              "\n",
              "    .dataframe thead th {\n",
              "        text-align: right;\n",
              "    }\n",
              "</style>\n",
              "<table border=\"1\" class=\"dataframe\">\n",
              "  <thead>\n",
              "    <tr style=\"text-align: right;\">\n",
              "      <th></th>\n",
              "      <th>CRIM</th>\n",
              "      <th>ZN</th>\n",
              "      <th>RM</th>\n",
              "      <th>AGE</th>\n",
              "      <th>TAX</th>\n",
              "      <th>PTRATIO</th>\n",
              "      <th>B</th>\n",
              "      <th>LSTAT</th>\n",
              "      <th>target</th>\n",
              "      <th>own</th>\n",
              "    </tr>\n",
              "  </thead>\n",
              "  <tbody>\n",
              "    <tr>\n",
              "      <th>0</th>\n",
              "      <td>0.00632</td>\n",
              "      <td>18.0</td>\n",
              "      <td>6.575</td>\n",
              "      <td>65.2</td>\n",
              "      <td>296.0</td>\n",
              "      <td>15.3</td>\n",
              "      <td>396.90</td>\n",
              "      <td>4.98</td>\n",
              "      <td>24.0</td>\n",
              "      <td>1.0</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <th>284</th>\n",
              "      <td>0.00906</td>\n",
              "      <td>90.0</td>\n",
              "      <td>7.088</td>\n",
              "      <td>20.8</td>\n",
              "      <td>285.0</td>\n",
              "      <td>15.3</td>\n",
              "      <td>394.72</td>\n",
              "      <td>7.85</td>\n",
              "      <td>32.2</td>\n",
              "      <td>1.0</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <th>285</th>\n",
              "      <td>0.01096</td>\n",
              "      <td>55.0</td>\n",
              "      <td>6.453</td>\n",
              "      <td>31.9</td>\n",
              "      <td>300.0</td>\n",
              "      <td>15.3</td>\n",
              "      <td>394.72</td>\n",
              "      <td>8.23</td>\n",
              "      <td>22.0</td>\n",
              "      <td>1.0</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <th>341</th>\n",
              "      <td>0.01301</td>\n",
              "      <td>35.0</td>\n",
              "      <td>7.241</td>\n",
              "      <td>49.3</td>\n",
              "      <td>284.0</td>\n",
              "      <td>15.5</td>\n",
              "      <td>394.74</td>\n",
              "      <td>5.49</td>\n",
              "      <td>32.7</td>\n",
              "      <td>1.0</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <th>55</th>\n",
              "      <td>0.01311</td>\n",
              "      <td>90.0</td>\n",
              "      <td>7.249</td>\n",
              "      <td>21.9</td>\n",
              "      <td>226.0</td>\n",
              "      <td>17.9</td>\n",
              "      <td>395.93</td>\n",
              "      <td>4.81</td>\n",
              "      <td>35.4</td>\n",
              "      <td>1.0</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <th>54</th>\n",
              "      <td>0.01360</td>\n",
              "      <td>75.0</td>\n",
              "      <td>5.888</td>\n",
              "      <td>47.6</td>\n",
              "      <td>469.0</td>\n",
              "      <td>21.1</td>\n",
              "      <td>396.90</td>\n",
              "      <td>14.80</td>\n",
              "      <td>18.9</td>\n",
              "      <td>1.0</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <th>195</th>\n",
              "      <td>0.01381</td>\n",
              "      <td>80.0</td>\n",
              "      <td>7.875</td>\n",
              "      <td>32.0</td>\n",
              "      <td>255.0</td>\n",
              "      <td>14.4</td>\n",
              "      <td>394.23</td>\n",
              "      <td>2.97</td>\n",
              "      <td>50.0</td>\n",
              "      <td>1.0</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <th>57</th>\n",
              "      <td>0.01432</td>\n",
              "      <td>100.0</td>\n",
              "      <td>6.816</td>\n",
              "      <td>40.5</td>\n",
              "      <td>256.0</td>\n",
              "      <td>15.1</td>\n",
              "      <td>392.90</td>\n",
              "      <td>3.95</td>\n",
              "      <td>31.6</td>\n",
              "      <td>1.0</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <th>194</th>\n",
              "      <td>0.01439</td>\n",
              "      <td>60.0</td>\n",
              "      <td>6.604</td>\n",
              "      <td>18.8</td>\n",
              "      <td>265.0</td>\n",
              "      <td>15.6</td>\n",
              "      <td>376.70</td>\n",
              "      <td>4.38</td>\n",
              "      <td>29.1</td>\n",
              "      <td>1.0</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <th>348</th>\n",
              "      <td>0.01501</td>\n",
              "      <td>80.0</td>\n",
              "      <td>6.635</td>\n",
              "      <td>29.7</td>\n",
              "      <td>280.0</td>\n",
              "      <td>17.0</td>\n",
              "      <td>390.94</td>\n",
              "      <td>5.99</td>\n",
              "      <td>24.5</td>\n",
              "      <td>1.0</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <th>0</th>\n",
              "      <td>0.00632</td>\n",
              "      <td>18.0</td>\n",
              "      <td>6.575</td>\n",
              "      <td>65.2</td>\n",
              "      <td>296.0</td>\n",
              "      <td>15.3</td>\n",
              "      <td>396.90</td>\n",
              "      <td>4.98</td>\n",
              "      <td>24.0</td>\n",
              "      <td>1.0</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <th>1</th>\n",
              "      <td>0.02731</td>\n",
              "      <td>0.0</td>\n",
              "      <td>6.421</td>\n",
              "      <td>78.9</td>\n",
              "      <td>242.0</td>\n",
              "      <td>17.8</td>\n",
              "      <td>396.90</td>\n",
              "      <td>9.14</td>\n",
              "      <td>21.6</td>\n",
              "      <td>0.0</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <th>2</th>\n",
              "      <td>0.02729</td>\n",
              "      <td>0.0</td>\n",
              "      <td>7.185</td>\n",
              "      <td>61.1</td>\n",
              "      <td>242.0</td>\n",
              "      <td>17.8</td>\n",
              "      <td>392.83</td>\n",
              "      <td>4.03</td>\n",
              "      <td>34.7</td>\n",
              "      <td>0.0</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <th>3</th>\n",
              "      <td>0.03237</td>\n",
              "      <td>0.0</td>\n",
              "      <td>6.998</td>\n",
              "      <td>45.8</td>\n",
              "      <td>222.0</td>\n",
              "      <td>18.7</td>\n",
              "      <td>394.63</td>\n",
              "      <td>2.94</td>\n",
              "      <td>33.4</td>\n",
              "      <td>0.0</td>\n",
              "    </tr>\n",
              "  </tbody>\n",
              "</table>\n",
              "</div>"
            ],
            "text/plain": [
              "        CRIM     ZN     RM   AGE    TAX  PTRATIO       B  LSTAT  target  own\n",
              "0    0.00632   18.0  6.575  65.2  296.0     15.3  396.90   4.98    24.0  1.0\n",
              "284  0.00906   90.0  7.088  20.8  285.0     15.3  394.72   7.85    32.2  1.0\n",
              "285  0.01096   55.0  6.453  31.9  300.0     15.3  394.72   8.23    22.0  1.0\n",
              "341  0.01301   35.0  7.241  49.3  284.0     15.5  394.74   5.49    32.7  1.0\n",
              "55   0.01311   90.0  7.249  21.9  226.0     17.9  395.93   4.81    35.4  1.0\n",
              "54   0.01360   75.0  5.888  47.6  469.0     21.1  396.90  14.80    18.9  1.0\n",
              "195  0.01381   80.0  7.875  32.0  255.0     14.4  394.23   2.97    50.0  1.0\n",
              "57   0.01432  100.0  6.816  40.5  256.0     15.1  392.90   3.95    31.6  1.0\n",
              "194  0.01439   60.0  6.604  18.8  265.0     15.6  376.70   4.38    29.1  1.0\n",
              "348  0.01501   80.0  6.635  29.7  280.0     17.0  390.94   5.99    24.5  1.0\n",
              "0    0.00632   18.0  6.575  65.2  296.0     15.3  396.90   4.98    24.0  1.0\n",
              "1    0.02731    0.0  6.421  78.9  242.0     17.8  396.90   9.14    21.6  0.0\n",
              "2    0.02729    0.0  7.185  61.1  242.0     17.8  392.83   4.03    34.7  0.0\n",
              "3    0.03237    0.0  6.998  45.8  222.0     18.7  394.63   2.94    33.4  0.0"
            ]
          },
          "metadata": {
            "tags": []
          },
          "execution_count": 10
        }
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "xvuadsmyitV4",
        "colab_type": "code",
        "colab": {
          "base_uri": "https://localhost:8080/",
          "height": 142
        },
        "outputId": "2351f137-6e0a-4949-990a-ef9f2a0e9b45"
      },
      "source": [
        "X = df_new.drop(['own'],axis=1) # Features\n",
        "y = df_new['own'] # Target variable\n",
        "\n",
        "def non_shuffling_train_test_split(X, y, test_size):\n",
        "    i = int((1 - test_size) * X.shape[0]) + 1\n",
        "    X_train, X_test = np.split(X, [i])\n",
        "    y_train, y_test = np.split(y, [i])\n",
        "    return X_train, X_test, y_train, y_test\n",
        "\n",
        "\n",
        "X_train, X_test, y_train, y_test = non_shuffling_train_test_split(X, y, test_size=0.85)\n",
        "\n",
        "X_train.head(3)"
      ],
      "execution_count": 11,
      "outputs": [
        {
          "output_type": "execute_result",
          "data": {
            "text/html": [
              "<div>\n",
              "<style scoped>\n",
              "    .dataframe tbody tr th:only-of-type {\n",
              "        vertical-align: middle;\n",
              "    }\n",
              "\n",
              "    .dataframe tbody tr th {\n",
              "        vertical-align: top;\n",
              "    }\n",
              "\n",
              "    .dataframe thead th {\n",
              "        text-align: right;\n",
              "    }\n",
              "</style>\n",
              "<table border=\"1\" class=\"dataframe\">\n",
              "  <thead>\n",
              "    <tr style=\"text-align: right;\">\n",
              "      <th></th>\n",
              "      <th>CRIM</th>\n",
              "      <th>ZN</th>\n",
              "      <th>RM</th>\n",
              "      <th>AGE</th>\n",
              "      <th>TAX</th>\n",
              "      <th>PTRATIO</th>\n",
              "      <th>B</th>\n",
              "      <th>LSTAT</th>\n",
              "      <th>target</th>\n",
              "    </tr>\n",
              "  </thead>\n",
              "  <tbody>\n",
              "    <tr>\n",
              "      <th>0</th>\n",
              "      <td>0.00632</td>\n",
              "      <td>18.0</td>\n",
              "      <td>6.575</td>\n",
              "      <td>65.2</td>\n",
              "      <td>296.0</td>\n",
              "      <td>15.3</td>\n",
              "      <td>396.90</td>\n",
              "      <td>4.98</td>\n",
              "      <td>24.0</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <th>284</th>\n",
              "      <td>0.00906</td>\n",
              "      <td>90.0</td>\n",
              "      <td>7.088</td>\n",
              "      <td>20.8</td>\n",
              "      <td>285.0</td>\n",
              "      <td>15.3</td>\n",
              "      <td>394.72</td>\n",
              "      <td>7.85</td>\n",
              "      <td>32.2</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <th>285</th>\n",
              "      <td>0.01096</td>\n",
              "      <td>55.0</td>\n",
              "      <td>6.453</td>\n",
              "      <td>31.9</td>\n",
              "      <td>300.0</td>\n",
              "      <td>15.3</td>\n",
              "      <td>394.72</td>\n",
              "      <td>8.23</td>\n",
              "      <td>22.0</td>\n",
              "    </tr>\n",
              "  </tbody>\n",
              "</table>\n",
              "</div>"
            ],
            "text/plain": [
              "        CRIM    ZN     RM   AGE    TAX  PTRATIO       B  LSTAT  target\n",
              "0    0.00632  18.0  6.575  65.2  296.0     15.3  396.90   4.98    24.0\n",
              "284  0.00906  90.0  7.088  20.8  285.0     15.3  394.72   7.85    32.2\n",
              "285  0.01096  55.0  6.453  31.9  300.0     15.3  394.72   8.23    22.0"
            ]
          },
          "metadata": {
            "tags": []
          },
          "execution_count": 11
        }
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "-0W25rPe-49G",
        "colab_type": "text"
      },
      "source": [
        "## Testing models\n"
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "Ij01aOZjaPDA",
        "colab_type": "code",
        "colab": {
          "base_uri": "https://localhost:8080/",
          "height": 34
        },
        "outputId": "c9e508dd-ec38-40a9-ec5d-553cedbed777"
      },
      "source": [
        "clf = DecisionTreeClassifier()\n",
        "clf.fit(X_train,y_train)\n",
        "y_pred = clf.predict(X_test)\n",
        "print(\"Accuracy:\",metrics.accuracy_score(y_test, y_pred))\n"
      ],
      "execution_count": 12,
      "outputs": [
        {
          "output_type": "stream",
          "text": [
            "Accuracy: 0.997716894977169\n"
          ],
          "name": "stdout"
        }
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "G4FceiA3aPFh",
        "colab_type": "code",
        "colab": {}
      },
      "source": [
        "#y_pred"
      ],
      "execution_count": 0,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "3nh_sxF4aPIX",
        "colab_type": "code",
        "colab": {}
      },
      "source": [
        "#np.array(y_test)"
      ],
      "execution_count": 0,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "Trxai87foMoc",
        "colab_type": "code",
        "colab": {
          "base_uri": "https://localhost:8080/",
          "height": 34
        },
        "outputId": "1ec044b8-83f5-408c-f331-6366c48d6553"
      },
      "source": [
        "clf0 = DecisionTreeClassifier(criterion=\"entropy\", max_depth=8)\n",
        "clf0.fit(X_train,y_train)\n",
        "y_pred = clf0.predict(X_test)\n",
        "print(\"Accuracy:\",metrics.accuracy_score(y_test, y_pred))\n"
      ],
      "execution_count": 15,
      "outputs": [
        {
          "output_type": "stream",
          "text": [
            "Accuracy: 0.997716894977169\n"
          ],
          "name": "stdout"
        }
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "fOps0QKLoMrE",
        "colab_type": "code",
        "colab": {
          "base_uri": "https://localhost:8080/",
          "height": 68
        },
        "outputId": "1e67e8bb-880e-437c-99e6-a386438d706c"
      },
      "source": [
        "clf = LinearSVC(random_state=0, tol=1e-5)\n",
        "clf.fit(X_train,y_train)\n",
        "y_pred = clf.predict(X_test)\n",
        "print(\"Accuracy:\",metrics.accuracy_score(y_test, y_pred))"
      ],
      "execution_count": 42,
      "outputs": [
        {
          "output_type": "stream",
          "text": [
            "Accuracy: 0.3310502283105023\n"
          ],
          "name": "stdout"
        },
        {
          "output_type": "stream",
          "text": [
            "/usr/local/lib/python3.6/dist-packages/sklearn/svm/base.py:929: ConvergenceWarning: Liblinear failed to converge, increase the number of iterations.\n",
            "  \"the number of iterations.\", ConvergenceWarning)\n"
          ],
          "name": "stderr"
        }
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "e7bOx87pV2_4",
        "colab_type": "code",
        "colab": {
          "base_uri": "https://localhost:8080/",
          "height": 88
        },
        "outputId": "a61820f7-e42d-4e52-edb2-4acbec89e567"
      },
      "source": [
        "from sklearn.svm import SVC\n",
        "clf = SVC(random_state=0, tol=1e-5)\n",
        "clf.fit(X_train,y_train)\n",
        "y_pred = clf.predict(X_test)\n",
        "print(\"Accuracy:\",metrics.accuracy_score(y_test, y_pred))"
      ],
      "execution_count": 43,
      "outputs": [
        {
          "output_type": "stream",
          "text": [
            "Accuracy: 0.9817351598173516\n"
          ],
          "name": "stdout"
        },
        {
          "output_type": "stream",
          "text": [
            "/usr/local/lib/python3.6/dist-packages/sklearn/svm/base.py:193: FutureWarning: The default value of gamma will change from 'auto' to 'scale' in version 0.22 to account better for unscaled features. Set gamma explicitly to 'auto' or 'scale' to avoid this warning.\n",
            "  \"avoid this warning.\", FutureWarning)\n"
          ],
          "name": "stderr"
        }
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "QLn1wyri0wdt",
        "colab_type": "code",
        "colab": {}
      },
      "source": [
        "# y_pred"
      ],
      "execution_count": 0,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "q2XtN3j_oMt7",
        "colab_type": "code",
        "colab": {}
      },
      "source": [
        "# np.array(y_test)"
      ],
      "execution_count": 0,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "wPY2wzpGosUK",
        "colab_type": "code",
        "colab": {
          "base_uri": "https://localhost:8080/",
          "height": 88
        },
        "outputId": "f63a6529-1186-4bcd-81e7-ef1934290c15"
      },
      "source": [
        "clf = OneClassSVM()\n",
        "clf.fit(X_train,y_train)\n",
        "y_pred = clf.predict(X_test)\n",
        "print(\"Accuracy:\",metrics.accuracy_score(y_test, y_pred))"
      ],
      "execution_count": 19,
      "outputs": [
        {
          "output_type": "stream",
          "text": [
            "Accuracy: 0.01141552511415525\n"
          ],
          "name": "stdout"
        },
        {
          "output_type": "stream",
          "text": [
            "/usr/local/lib/python3.6/dist-packages/sklearn/svm/base.py:193: FutureWarning: The default value of gamma will change from 'auto' to 'scale' in version 0.22 to account better for unscaled features. Set gamma explicitly to 'auto' or 'scale' to avoid this warning.\n",
            "  \"avoid this warning.\", FutureWarning)\n"
          ],
          "name": "stderr"
        }
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "uP2y-2e8oMwo",
        "colab_type": "code",
        "colab": {
          "base_uri": "https://localhost:8080/",
          "height": 255
        },
        "outputId": "7b06af1f-607a-4e8b-e3d7-46060ee4caf0"
      },
      "source": [
        "for i in range(1,15):\n",
        "  knn = KNeighborsClassifier(n_neighbors=i)\n",
        "  knn.fit(X_train, y_train)\n",
        "  y_pred = knn.predict(X_test)\n",
        "  print('I: {0}, Accuracy: {1}'.format(i, metrics.accuracy_score(y_test, y_pred)))"
      ],
      "execution_count": 20,
      "outputs": [
        {
          "output_type": "stream",
          "text": [
            "I: 1, Accuracy: 0.6095890410958904\n",
            "I: 2, Accuracy: 0.6484018264840182\n",
            "I: 3, Accuracy: 0.636986301369863\n",
            "I: 4, Accuracy: 0.9794520547945206\n",
            "I: 5, Accuracy: 0.958904109589041\n",
            "I: 6, Accuracy: 0.9634703196347032\n",
            "I: 7, Accuracy: 0.958904109589041\n",
            "I: 8, Accuracy: 0.958904109589041\n",
            "I: 9, Accuracy: 0.9611872146118722\n",
            "I: 10, Accuracy: 0.9680365296803652\n",
            "I: 11, Accuracy: 0.958904109589041\n",
            "I: 12, Accuracy: 0.9703196347031964\n",
            "I: 13, Accuracy: 0.9680365296803652\n",
            "I: 14, Accuracy: 0.9703196347031964\n"
          ],
          "name": "stdout"
        }
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "5mgw5uYhspBO",
        "colab_type": "code",
        "colab": {
          "base_uri": "https://localhost:8080/",
          "height": 34
        },
        "outputId": "79f02303-7188-4891-8c13-d229d5f827b5"
      },
      "source": [
        "knn = KNeighborsClassifier(n_neighbors=5)\n",
        "knn.fit(X_train, y_train)\n",
        "y_pred = knn.predict(X_test)\n",
        "print('I: {0}, Accuracy: {1}'.format(i, metrics.accuracy_score(y_test, y_pred)))\n"
      ],
      "execution_count": 21,
      "outputs": [
        {
          "output_type": "stream",
          "text": [
            "I: 14, Accuracy: 0.958904109589041\n"
          ],
          "name": "stdout"
        }
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "TM8S50zKsuO9",
        "colab_type": "code",
        "colab": {}
      },
      "source": [
        "#y_pred"
      ],
      "execution_count": 0,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "AAbHWL-h42Xa",
        "colab_type": "code",
        "colab": {}
      },
      "source": [
        "# np.array(y_test)"
      ],
      "execution_count": 0,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "eEbBU2-542ai",
        "colab_type": "code",
        "colab": {}
      },
      "source": [
        ""
      ],
      "execution_count": 0,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "ylYwOAaB42dC",
        "colab_type": "code",
        "colab": {
          "base_uri": "https://localhost:8080/",
          "height": 34
        },
        "outputId": "6b766f34-368e-46eb-864d-05df2c8570b1"
      },
      "source": [
        "G_NB = GaussianNB()\n",
        "G_NB.fit(X_train, y_train)\n",
        "y_pred = G_NB.predict(X_test)\n",
        "print('GaussianNB: Accuracy: {0}'.format(metrics.accuracy_score(y_test, y_pred)))"
      ],
      "execution_count": 24,
      "outputs": [
        {
          "output_type": "stream",
          "text": [
            "GaussianNB: Accuracy: 0.9748858447488584\n"
          ],
          "name": "stdout"
        }
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "XnFu2olHEM6W",
        "colab_type": "code",
        "colab": {
          "base_uri": "https://localhost:8080/",
          "height": 34
        },
        "outputId": "1e959d4a-e993-4d33-bcb8-02b2e1d2fb79"
      },
      "source": [
        "B_NB = BernoulliNB()\n",
        "B_NB.fit(X_train, y_train)\n",
        "y_pred = B_NB.predict(X_test)\n",
        "print('BernoulliNB: Accuracy: {0}'.format(metrics.accuracy_score(y_test, y_pred)))"
      ],
      "execution_count": 25,
      "outputs": [
        {
          "output_type": "stream",
          "text": [
            "BernoulliNB: Accuracy: 0.9680365296803652\n"
          ],
          "name": "stdout"
        }
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "xATyYm2MEM9s",
        "colab_type": "code",
        "colab": {
          "base_uri": "https://localhost:8080/",
          "height": 34
        },
        "outputId": "f7cf96c2-d0cf-4bf6-f173-6b1d75a11cd9"
      },
      "source": [
        "M_NB = MultinomialNB()\n",
        "M_NB.fit(X_train, y_train)\n",
        "y_pred = M_NB.predict(X_test)\n",
        "print('MultinomialNB: Accuracy: {0}'.format(metrics.accuracy_score(y_test, y_pred)))"
      ],
      "execution_count": 44,
      "outputs": [
        {
          "output_type": "stream",
          "text": [
            "MultinomialNB: Accuracy: 0.8721461187214612\n"
          ],
          "name": "stdout"
        }
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "7GgoNchMENAg",
        "colab_type": "code",
        "colab": {
          "base_uri": "https://localhost:8080/",
          "height": 34
        },
        "outputId": "56b698df-bc8c-4f02-e8e1-091ec05309da"
      },
      "source": [
        "C_NB = ComplementNB()\n",
        "C_NB.fit(X_train, y_train)\n",
        "y_pred = C_NB.predict(X_test)\n",
        "print('ComplementNB: Accuracy: {0}'.format(metrics.accuracy_score(y_test, y_pred)))"
      ],
      "execution_count": 45,
      "outputs": [
        {
          "output_type": "stream",
          "text": [
            "ComplementNB: Accuracy: 0.8698630136986302\n"
          ],
          "name": "stdout"
        }
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "ey2HChC1FIwk",
        "colab_type": "code",
        "colab": {
          "base_uri": "https://localhost:8080/",
          "height": 357
        },
        "outputId": "c00a22f1-e9dc-434b-e726-cf09cfb77e0c"
      },
      "source": [
        "clf1 = LogisticRegression(solver='lbfgs', multi_class='multinomial',                        random_state=1)\n",
        "clf2 = RandomForestClassifier(n_estimators=50, random_state=1)\n",
        "clf3 = GaussianNB()\n",
        "\n",
        "eclf = VotingClassifier(estimators=[('lr', clf1), ('rf', clf2), ('gnb', clf3)], voting='hard')\n",
        "\n",
        "for clf, label in zip([clf1, clf2, clf3, eclf], ['Logistic Regression', 'Random Forest', 'naive Bayes', 'Ensemble']):\n",
        "     scores = cross_val_score(clf, X, y, cv=5, scoring='accuracy')\n",
        "     print(\"Accuracy: %0.2f (+/- %0.2f) [%s]\" % (scores.mean(), scores.std(), label))"
      ],
      "execution_count": 28,
      "outputs": [
        {
          "output_type": "stream",
          "text": [
            "/usr/local/lib/python3.6/dist-packages/sklearn/linear_model/logistic.py:947: ConvergenceWarning: lbfgs failed to converge. Increase the number of iterations.\n",
            "  \"of iterations.\", ConvergenceWarning)\n",
            "/usr/local/lib/python3.6/dist-packages/sklearn/linear_model/logistic.py:947: ConvergenceWarning: lbfgs failed to converge. Increase the number of iterations.\n",
            "  \"of iterations.\", ConvergenceWarning)\n",
            "/usr/local/lib/python3.6/dist-packages/sklearn/linear_model/logistic.py:947: ConvergenceWarning: lbfgs failed to converge. Increase the number of iterations.\n",
            "  \"of iterations.\", ConvergenceWarning)\n",
            "/usr/local/lib/python3.6/dist-packages/sklearn/linear_model/logistic.py:947: ConvergenceWarning: lbfgs failed to converge. Increase the number of iterations.\n",
            "  \"of iterations.\", ConvergenceWarning)\n"
          ],
          "name": "stderr"
        },
        {
          "output_type": "stream",
          "text": [
            "Accuracy: 0.95 (+/- 0.03) [Logistic Regression]\n",
            "Accuracy: 0.99 (+/- 0.00) [Random Forest]\n",
            "Accuracy: 0.93 (+/- 0.04) [naive Bayes]\n"
          ],
          "name": "stdout"
        },
        {
          "output_type": "stream",
          "text": [
            "/usr/local/lib/python3.6/dist-packages/sklearn/linear_model/logistic.py:947: ConvergenceWarning: lbfgs failed to converge. Increase the number of iterations.\n",
            "  \"of iterations.\", ConvergenceWarning)\n",
            "/usr/local/lib/python3.6/dist-packages/sklearn/linear_model/logistic.py:947: ConvergenceWarning: lbfgs failed to converge. Increase the number of iterations.\n",
            "  \"of iterations.\", ConvergenceWarning)\n",
            "/usr/local/lib/python3.6/dist-packages/sklearn/linear_model/logistic.py:947: ConvergenceWarning: lbfgs failed to converge. Increase the number of iterations.\n",
            "  \"of iterations.\", ConvergenceWarning)\n",
            "/usr/local/lib/python3.6/dist-packages/sklearn/linear_model/logistic.py:947: ConvergenceWarning: lbfgs failed to converge. Increase the number of iterations.\n",
            "  \"of iterations.\", ConvergenceWarning)\n"
          ],
          "name": "stderr"
        },
        {
          "output_type": "stream",
          "text": [
            "Accuracy: 0.97 (+/- 0.03) [Ensemble]\n"
          ],
          "name": "stdout"
        }
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "9R4jn8kpMrff",
        "colab_type": "code",
        "colab": {
          "base_uri": "https://localhost:8080/",
          "height": 136
        },
        "outputId": "11c40d1a-02f3-4081-e484-c58c0994ef66"
      },
      "source": [
        "clf1 =GradientBoostingClassifier()\n",
        "clf2 = RandomForestClassifier(n_estimators=20, random_state=1)\n",
        "clf3 = GaussianNB()\n",
        "\n",
        "eclf = VotingClassifier(estimators=[('GradientBoostingClassifier', clf1), ('rf', clf2), ('gnb', clf3),('DecisionTreeClassifier', clf0),('knn', knn),('BernoulliNB',B_NB)], voting='hard') #soft\n",
        "l1 = [clf1, clf2, clf3, B_NB, knn, B_NB,eclf]\n",
        "l2 = ['GradientBoostingClassifier', 'Random Forest', 'naive Bayes','DecisionTreeClassifier','KNN','BernoulliNB', 'Ensemble']\n",
        "for clf, label in zip(l1,l2):\n",
        "     scores = cross_val_score(clf, X, y, cv=5, scoring='accuracy')\n",
        "     print(\"Accuracy: %0.2f (+/- %0.2f) [%s]\" % (scores.mean(), scores.std(), label))"
      ],
      "execution_count": 29,
      "outputs": [
        {
          "output_type": "stream",
          "text": [
            "Accuracy: 1.00 (+/- 0.00) [GradientBoostingClassifier]\n",
            "Accuracy: 1.00 (+/- 0.00) [Random Forest]\n",
            "Accuracy: 0.93 (+/- 0.04) [naive Bayes]\n",
            "Accuracy: 0.94 (+/- 0.00) [DecisionTreeClassifier]\n",
            "Accuracy: 0.95 (+/- 0.02) [KNN]\n",
            "Accuracy: 0.94 (+/- 0.00) [BernoulliNB]\n",
            "Accuracy: 0.99 (+/- 0.00) [Ensemble]\n"
          ],
          "name": "stdout"
        }
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "ZTsiPUwAMriQ",
        "colab_type": "code",
        "colab": {
          "base_uri": "https://localhost:8080/",
          "height": 153
        },
        "outputId": "939b7b02-2c87-4e7b-a6fc-d0402d3ee671"
      },
      "source": [
        "clf1 =GradientBoostingClassifier() \n",
        "clf2 = RandomForestClassifier(n_estimators=20, random_state=1)\n",
        "clf3 = GaussianNB()\n",
        "clf4 = AdaBoostClassifier()\n",
        "\n",
        "eclf = VotingClassifier(estimators=[('GradientBoostingClassifier', clf1), ('rf', clf2), ('gnb', clf3),('DecisionTreeClassifier', clf0),('knn', knn),('BernoulliNB',B_NB),('AdaBoostClassifier',clf4)], voting='soft') #soft\n",
        "l1 = [clf1, clf2, clf3, B_NB, knn, B_NB,clf4,eclf]\n",
        "l2 = ['GradientBoostingClassifier', 'Random Forest', 'naive Bayes','DecisionTreeClassifier','KNN','BernoulliNB','AdaBoostClassifier', 'Ensemble']\n",
        "for clf, label in zip(l1,l2):\n",
        "     scores = cross_val_score(clf, X, y, cv=5, scoring='accuracy')\n",
        "     print(\"Accuracy: %0.2f (+/- %0.2f) [%s]\" % (scores.mean(), scores.std(), label))"
      ],
      "execution_count": 30,
      "outputs": [
        {
          "output_type": "stream",
          "text": [
            "Accuracy: 1.00 (+/- 0.00) [GradientBoostingClassifier]\n",
            "Accuracy: 1.00 (+/- 0.00) [Random Forest]\n",
            "Accuracy: 0.93 (+/- 0.04) [naive Bayes]\n",
            "Accuracy: 0.94 (+/- 0.00) [DecisionTreeClassifier]\n",
            "Accuracy: 0.95 (+/- 0.02) [KNN]\n",
            "Accuracy: 0.94 (+/- 0.00) [BernoulliNB]\n",
            "Accuracy: 1.00 (+/- 0.00) [AdaBoostClassifier]\n",
            "Accuracy: 1.00 (+/- 0.00) [Ensemble]\n"
          ],
          "name": "stdout"
        }
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "qTEwokYjFIzJ",
        "colab_type": "code",
        "colab": {
          "base_uri": "https://localhost:8080/",
          "height": 510
        },
        "outputId": "8a37d4bf-ac69-48a9-d43b-3bef2aafc25d"
      },
      "source": [
        "eclf.fit(X_train,y_train)\n",
        "#np.array(eclf.predict(X_test) == y_test)"
      ],
      "execution_count": 31,
      "outputs": [
        {
          "output_type": "execute_result",
          "data": {
            "text/plain": [
              "VotingClassifier(estimators=[('GradientBoostingClassifier',\n",
              "                              GradientBoostingClassifier(criterion='friedman_mse',\n",
              "                                                         init=None,\n",
              "                                                         learning_rate=0.1,\n",
              "                                                         loss='deviance',\n",
              "                                                         max_depth=3,\n",
              "                                                         max_features=None,\n",
              "                                                         max_leaf_nodes=None,\n",
              "                                                         min_impurity_decrease=0.0,\n",
              "                                                         min_impurity_split=None,\n",
              "                                                         min_samples_leaf=1,\n",
              "                                                         min_samples_split=2,\n",
              "                                                         min_weight_fraction_leaf=0.0,\n",
              "                                                         n_estimators=100,\n",
              "                                                         n_iter_no_...\n",
              "                                                   metric_params=None,\n",
              "                                                   n_jobs=None, n_neighbors=5,\n",
              "                                                   p=2, weights='uniform')),\n",
              "                             ('BernoulliNB',\n",
              "                              BernoulliNB(alpha=1.0, binarize=0.0,\n",
              "                                          class_prior=None, fit_prior=True)),\n",
              "                             ('AdaBoostClassifier',\n",
              "                              AdaBoostClassifier(algorithm='SAMME.R',\n",
              "                                                 base_estimator=None,\n",
              "                                                 learning_rate=1.0,\n",
              "                                                 n_estimators=50,\n",
              "                                                 random_state=None))],\n",
              "                 flatten_transform=True, n_jobs=None, voting='soft',\n",
              "                 weights=None)"
            ]
          },
          "metadata": {
            "tags": []
          },
          "execution_count": 31
        }
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "PkLM3mjmow9U",
        "colab_type": "text"
      },
      "source": [
        "## Final results \n"
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "uTsjFSBhENF0",
        "colab_type": "code",
        "colab": {
          "base_uri": "https://localhost:8080/",
          "height": 204
        },
        "outputId": "8508be31-6d6a-491f-9eb5-f4feef11eb1c"
      },
      "source": [
        "#X_train, X_test, y_train, y_test = non_shuffling_train_test_split(X, y, test_size=0.85)\n",
        "\n",
        "df_prediction = X_test.copy()\n",
        "df_prediction['prob'] = eclf.predict_proba(X_test)[:,1]\n",
        "df_prediction['own'] = y_test\n",
        "df_prediction = df_prediction[df_prediction['own']==0]\n",
        "df_prediction= df_prediction.sort_values(['prob'],ascending=False,axis=0)\n",
        "df_prediction.head(5)"
      ],
      "execution_count": 32,
      "outputs": [
        {
          "output_type": "execute_result",
          "data": {
            "text/html": [
              "<div>\n",
              "<style scoped>\n",
              "    .dataframe tbody tr th:only-of-type {\n",
              "        vertical-align: middle;\n",
              "    }\n",
              "\n",
              "    .dataframe tbody tr th {\n",
              "        vertical-align: top;\n",
              "    }\n",
              "\n",
              "    .dataframe thead th {\n",
              "        text-align: right;\n",
              "    }\n",
              "</style>\n",
              "<table border=\"1\" class=\"dataframe\">\n",
              "  <thead>\n",
              "    <tr style=\"text-align: right;\">\n",
              "      <th></th>\n",
              "      <th>CRIM</th>\n",
              "      <th>ZN</th>\n",
              "      <th>RM</th>\n",
              "      <th>AGE</th>\n",
              "      <th>TAX</th>\n",
              "      <th>PTRATIO</th>\n",
              "      <th>B</th>\n",
              "      <th>LSTAT</th>\n",
              "      <th>target</th>\n",
              "      <th>prob</th>\n",
              "      <th>own</th>\n",
              "    </tr>\n",
              "  </thead>\n",
              "  <tbody>\n",
              "    <tr>\n",
              "      <th>193</th>\n",
              "      <td>0.02187</td>\n",
              "      <td>60.0</td>\n",
              "      <td>6.800</td>\n",
              "      <td>9.9</td>\n",
              "      <td>265.0</td>\n",
              "      <td>15.6</td>\n",
              "      <td>393.37</td>\n",
              "      <td>5.03</td>\n",
              "      <td>31.1</td>\n",
              "      <td>0.839557</td>\n",
              "      <td>0.0</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <th>203</th>\n",
              "      <td>0.03510</td>\n",
              "      <td>95.0</td>\n",
              "      <td>7.853</td>\n",
              "      <td>33.2</td>\n",
              "      <td>224.0</td>\n",
              "      <td>14.7</td>\n",
              "      <td>392.78</td>\n",
              "      <td>3.81</td>\n",
              "      <td>48.5</td>\n",
              "      <td>0.403947</td>\n",
              "      <td>0.0</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <th>198</th>\n",
              "      <td>0.03768</td>\n",
              "      <td>80.0</td>\n",
              "      <td>7.274</td>\n",
              "      <td>38.3</td>\n",
              "      <td>329.0</td>\n",
              "      <td>12.6</td>\n",
              "      <td>392.20</td>\n",
              "      <td>6.62</td>\n",
              "      <td>34.6</td>\n",
              "      <td>0.336496</td>\n",
              "      <td>0.0</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <th>199</th>\n",
              "      <td>0.03150</td>\n",
              "      <td>95.0</td>\n",
              "      <td>6.975</td>\n",
              "      <td>15.3</td>\n",
              "      <td>402.0</td>\n",
              "      <td>17.0</td>\n",
              "      <td>396.90</td>\n",
              "      <td>4.56</td>\n",
              "      <td>34.9</td>\n",
              "      <td>0.303947</td>\n",
              "      <td>0.0</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <th>344</th>\n",
              "      <td>0.03049</td>\n",
              "      <td>55.0</td>\n",
              "      <td>6.874</td>\n",
              "      <td>28.1</td>\n",
              "      <td>370.0</td>\n",
              "      <td>17.6</td>\n",
              "      <td>387.97</td>\n",
              "      <td>4.61</td>\n",
              "      <td>31.2</td>\n",
              "      <td>0.295907</td>\n",
              "      <td>0.0</td>\n",
              "    </tr>\n",
              "  </tbody>\n",
              "</table>\n",
              "</div>"
            ],
            "text/plain": [
              "        CRIM    ZN     RM   AGE    TAX  ...       B  LSTAT  target      prob  own\n",
              "193  0.02187  60.0  6.800   9.9  265.0  ...  393.37   5.03    31.1  0.839557  0.0\n",
              "203  0.03510  95.0  7.853  33.2  224.0  ...  392.78   3.81    48.5  0.403947  0.0\n",
              "198  0.03768  80.0  7.274  38.3  329.0  ...  392.20   6.62    34.6  0.336496  0.0\n",
              "199  0.03150  95.0  6.975  15.3  402.0  ...  396.90   4.56    34.9  0.303947  0.0\n",
              "344  0.03049  55.0  6.874  28.1  370.0  ...  387.97   4.61    31.2  0.295907  0.0\n",
              "\n",
              "[5 rows x 11 columns]"
            ]
          },
          "metadata": {
            "tags": []
          },
          "execution_count": 32
        }
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "c0m1uf8ricIO",
        "colab_type": "code",
        "colab": {
          "base_uri": "https://localhost:8080/",
          "height": 34
        },
        "outputId": "5d2a16d6-da8c-4cf2-eaa3-4289eef21315"
      },
      "source": [
        "print('next five places to consider buying are listing #{0}'.format(str(list(df_prediction.index[:5]))))"
      ],
      "execution_count": 33,
      "outputs": [
        {
          "output_type": "stream",
          "text": [
            "next five places to consider buying are listing #[193, 203, 198, 199, 344]\n"
          ],
          "name": "stdout"
        }
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "eLg2VcOlVKmi",
        "colab_type": "code",
        "colab": {
          "base_uri": "https://localhost:8080/",
          "height": 111
        },
        "outputId": "905b9369-26ef-4541-a357-fa6146ffe990"
      },
      "source": [
        "x = df.describe()\n",
        "x.iloc[[1,2]]"
      ],
      "execution_count": 70,
      "outputs": [
        {
          "output_type": "execute_result",
          "data": {
            "text/html": [
              "<div>\n",
              "<style scoped>\n",
              "    .dataframe tbody tr th:only-of-type {\n",
              "        vertical-align: middle;\n",
              "    }\n",
              "\n",
              "    .dataframe tbody tr th {\n",
              "        vertical-align: top;\n",
              "    }\n",
              "\n",
              "    .dataframe thead th {\n",
              "        text-align: right;\n",
              "    }\n",
              "</style>\n",
              "<table border=\"1\" class=\"dataframe\">\n",
              "  <thead>\n",
              "    <tr style=\"text-align: right;\">\n",
              "      <th></th>\n",
              "      <th>CRIM</th>\n",
              "      <th>ZN</th>\n",
              "      <th>RM</th>\n",
              "      <th>AGE</th>\n",
              "      <th>TAX</th>\n",
              "      <th>PTRATIO</th>\n",
              "      <th>B</th>\n",
              "      <th>LSTAT</th>\n",
              "      <th>target</th>\n",
              "      <th>own</th>\n",
              "    </tr>\n",
              "  </thead>\n",
              "  <tbody>\n",
              "    <tr>\n",
              "      <th>mean</th>\n",
              "      <td>3.613524</td>\n",
              "      <td>11.363636</td>\n",
              "      <td>6.284634</td>\n",
              "      <td>68.574901</td>\n",
              "      <td>408.237154</td>\n",
              "      <td>18.455534</td>\n",
              "      <td>356.674032</td>\n",
              "      <td>12.653063</td>\n",
              "      <td>22.532806</td>\n",
              "      <td>0.039526</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <th>std</th>\n",
              "      <td>8.601545</td>\n",
              "      <td>23.322453</td>\n",
              "      <td>0.702617</td>\n",
              "      <td>28.148861</td>\n",
              "      <td>168.537116</td>\n",
              "      <td>2.164946</td>\n",
              "      <td>91.294864</td>\n",
              "      <td>7.141062</td>\n",
              "      <td>9.197104</td>\n",
              "      <td>0.195035</td>\n",
              "    </tr>\n",
              "  </tbody>\n",
              "</table>\n",
              "</div>"
            ],
            "text/plain": [
              "          CRIM         ZN        RM  ...      LSTAT     target       own\n",
              "mean  3.613524  11.363636  6.284634  ...  12.653063  22.532806  0.039526\n",
              "std   8.601545  23.322453  0.702617  ...   7.141062   9.197104  0.195035\n",
              "\n",
              "[2 rows x 10 columns]"
            ]
          },
          "metadata": {
            "tags": []
          },
          "execution_count": 70
        }
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "qm4v2RR5pjid",
        "colab_type": "text"
      },
      "source": [
        "# Let's try for fancy new age methods \n",
        "\n",
        "### if you can read this, this is not done yet.... gotta learn new stuff. switching to movielens dataset, since i can copy,paste and modify others code to learn quickly"
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "VF8dHqCwgkye",
        "colab_type": "code",
        "colab": {
          "base_uri": "https://localhost:8080/",
          "height": 514
        },
        "outputId": "f64777b0-7466-4f71-d71f-034342a2199a"
      },
      "source": [
        "import gc \n",
        "gc.collect()\n",
        "df_boston = pd.DataFrame(boston.data,columns=boston.feature_names)\n",
        "df_boston['target'] = pd.Series(boston.target)\n",
        "df = df_boston\n",
        "\n",
        "df =df_boston.drop(['NOX','CHAS','INDUS','DIS','RAD'],axis=1) \n",
        "# accuracy                           0.97       438\n",
        "# df =df_boston.drop(['NOX','CHAS'],axis=1)   \n",
        "# accuracy                           0.97       438\n",
        "\n",
        "df_byCRIM = df.sort_values('CRIM')\n",
        "\n",
        "own = np.zeros(len(df_byCRIM))\n",
        "own[:20] = 1 \n",
        "df_byCRIM['own'] = own\n",
        "\n",
        "df = df_byCRIM.sort_index()\n",
        "df.head(15)"
      ],
      "execution_count": 87,
      "outputs": [
        {
          "output_type": "execute_result",
          "data": {
            "text/html": [
              "<div>\n",
              "<style scoped>\n",
              "    .dataframe tbody tr th:only-of-type {\n",
              "        vertical-align: middle;\n",
              "    }\n",
              "\n",
              "    .dataframe tbody tr th {\n",
              "        vertical-align: top;\n",
              "    }\n",
              "\n",
              "    .dataframe thead th {\n",
              "        text-align: right;\n",
              "    }\n",
              "</style>\n",
              "<table border=\"1\" class=\"dataframe\">\n",
              "  <thead>\n",
              "    <tr style=\"text-align: right;\">\n",
              "      <th></th>\n",
              "      <th>CRIM</th>\n",
              "      <th>ZN</th>\n",
              "      <th>RM</th>\n",
              "      <th>AGE</th>\n",
              "      <th>TAX</th>\n",
              "      <th>PTRATIO</th>\n",
              "      <th>B</th>\n",
              "      <th>LSTAT</th>\n",
              "      <th>target</th>\n",
              "      <th>own</th>\n",
              "    </tr>\n",
              "  </thead>\n",
              "  <tbody>\n",
              "    <tr>\n",
              "      <th>0</th>\n",
              "      <td>0.00632</td>\n",
              "      <td>18.0</td>\n",
              "      <td>6.575</td>\n",
              "      <td>65.2</td>\n",
              "      <td>296.0</td>\n",
              "      <td>15.3</td>\n",
              "      <td>396.90</td>\n",
              "      <td>4.98</td>\n",
              "      <td>24.0</td>\n",
              "      <td>1.0</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <th>1</th>\n",
              "      <td>0.02731</td>\n",
              "      <td>0.0</td>\n",
              "      <td>6.421</td>\n",
              "      <td>78.9</td>\n",
              "      <td>242.0</td>\n",
              "      <td>17.8</td>\n",
              "      <td>396.90</td>\n",
              "      <td>9.14</td>\n",
              "      <td>21.6</td>\n",
              "      <td>0.0</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <th>2</th>\n",
              "      <td>0.02729</td>\n",
              "      <td>0.0</td>\n",
              "      <td>7.185</td>\n",
              "      <td>61.1</td>\n",
              "      <td>242.0</td>\n",
              "      <td>17.8</td>\n",
              "      <td>392.83</td>\n",
              "      <td>4.03</td>\n",
              "      <td>34.7</td>\n",
              "      <td>0.0</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <th>3</th>\n",
              "      <td>0.03237</td>\n",
              "      <td>0.0</td>\n",
              "      <td>6.998</td>\n",
              "      <td>45.8</td>\n",
              "      <td>222.0</td>\n",
              "      <td>18.7</td>\n",
              "      <td>394.63</td>\n",
              "      <td>2.94</td>\n",
              "      <td>33.4</td>\n",
              "      <td>0.0</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <th>4</th>\n",
              "      <td>0.06905</td>\n",
              "      <td>0.0</td>\n",
              "      <td>7.147</td>\n",
              "      <td>54.2</td>\n",
              "      <td>222.0</td>\n",
              "      <td>18.7</td>\n",
              "      <td>396.90</td>\n",
              "      <td>5.33</td>\n",
              "      <td>36.2</td>\n",
              "      <td>0.0</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <th>5</th>\n",
              "      <td>0.02985</td>\n",
              "      <td>0.0</td>\n",
              "      <td>6.430</td>\n",
              "      <td>58.7</td>\n",
              "      <td>222.0</td>\n",
              "      <td>18.7</td>\n",
              "      <td>394.12</td>\n",
              "      <td>5.21</td>\n",
              "      <td>28.7</td>\n",
              "      <td>0.0</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <th>6</th>\n",
              "      <td>0.08829</td>\n",
              "      <td>12.5</td>\n",
              "      <td>6.012</td>\n",
              "      <td>66.6</td>\n",
              "      <td>311.0</td>\n",
              "      <td>15.2</td>\n",
              "      <td>395.60</td>\n",
              "      <td>12.43</td>\n",
              "      <td>22.9</td>\n",
              "      <td>0.0</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <th>7</th>\n",
              "      <td>0.14455</td>\n",
              "      <td>12.5</td>\n",
              "      <td>6.172</td>\n",
              "      <td>96.1</td>\n",
              "      <td>311.0</td>\n",
              "      <td>15.2</td>\n",
              "      <td>396.90</td>\n",
              "      <td>19.15</td>\n",
              "      <td>27.1</td>\n",
              "      <td>0.0</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <th>8</th>\n",
              "      <td>0.21124</td>\n",
              "      <td>12.5</td>\n",
              "      <td>5.631</td>\n",
              "      <td>100.0</td>\n",
              "      <td>311.0</td>\n",
              "      <td>15.2</td>\n",
              "      <td>386.63</td>\n",
              "      <td>29.93</td>\n",
              "      <td>16.5</td>\n",
              "      <td>0.0</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <th>9</th>\n",
              "      <td>0.17004</td>\n",
              "      <td>12.5</td>\n",
              "      <td>6.004</td>\n",
              "      <td>85.9</td>\n",
              "      <td>311.0</td>\n",
              "      <td>15.2</td>\n",
              "      <td>386.71</td>\n",
              "      <td>17.10</td>\n",
              "      <td>18.9</td>\n",
              "      <td>0.0</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <th>10</th>\n",
              "      <td>0.22489</td>\n",
              "      <td>12.5</td>\n",
              "      <td>6.377</td>\n",
              "      <td>94.3</td>\n",
              "      <td>311.0</td>\n",
              "      <td>15.2</td>\n",
              "      <td>392.52</td>\n",
              "      <td>20.45</td>\n",
              "      <td>15.0</td>\n",
              "      <td>0.0</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <th>11</th>\n",
              "      <td>0.11747</td>\n",
              "      <td>12.5</td>\n",
              "      <td>6.009</td>\n",
              "      <td>82.9</td>\n",
              "      <td>311.0</td>\n",
              "      <td>15.2</td>\n",
              "      <td>396.90</td>\n",
              "      <td>13.27</td>\n",
              "      <td>18.9</td>\n",
              "      <td>0.0</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <th>12</th>\n",
              "      <td>0.09378</td>\n",
              "      <td>12.5</td>\n",
              "      <td>5.889</td>\n",
              "      <td>39.0</td>\n",
              "      <td>311.0</td>\n",
              "      <td>15.2</td>\n",
              "      <td>390.50</td>\n",
              "      <td>15.71</td>\n",
              "      <td>21.7</td>\n",
              "      <td>0.0</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <th>13</th>\n",
              "      <td>0.62976</td>\n",
              "      <td>0.0</td>\n",
              "      <td>5.949</td>\n",
              "      <td>61.8</td>\n",
              "      <td>307.0</td>\n",
              "      <td>21.0</td>\n",
              "      <td>396.90</td>\n",
              "      <td>8.26</td>\n",
              "      <td>20.4</td>\n",
              "      <td>0.0</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <th>14</th>\n",
              "      <td>0.63796</td>\n",
              "      <td>0.0</td>\n",
              "      <td>6.096</td>\n",
              "      <td>84.5</td>\n",
              "      <td>307.0</td>\n",
              "      <td>21.0</td>\n",
              "      <td>380.02</td>\n",
              "      <td>10.26</td>\n",
              "      <td>18.2</td>\n",
              "      <td>0.0</td>\n",
              "    </tr>\n",
              "  </tbody>\n",
              "</table>\n",
              "</div>"
            ],
            "text/plain": [
              "       CRIM    ZN     RM    AGE    TAX  PTRATIO       B  LSTAT  target  own\n",
              "0   0.00632  18.0  6.575   65.2  296.0     15.3  396.90   4.98    24.0  1.0\n",
              "1   0.02731   0.0  6.421   78.9  242.0     17.8  396.90   9.14    21.6  0.0\n",
              "2   0.02729   0.0  7.185   61.1  242.0     17.8  392.83   4.03    34.7  0.0\n",
              "3   0.03237   0.0  6.998   45.8  222.0     18.7  394.63   2.94    33.4  0.0\n",
              "4   0.06905   0.0  7.147   54.2  222.0     18.7  396.90   5.33    36.2  0.0\n",
              "5   0.02985   0.0  6.430   58.7  222.0     18.7  394.12   5.21    28.7  0.0\n",
              "6   0.08829  12.5  6.012   66.6  311.0     15.2  395.60  12.43    22.9  0.0\n",
              "7   0.14455  12.5  6.172   96.1  311.0     15.2  396.90  19.15    27.1  0.0\n",
              "8   0.21124  12.5  5.631  100.0  311.0     15.2  386.63  29.93    16.5  0.0\n",
              "9   0.17004  12.5  6.004   85.9  311.0     15.2  386.71  17.10    18.9  0.0\n",
              "10  0.22489  12.5  6.377   94.3  311.0     15.2  392.52  20.45    15.0  0.0\n",
              "11  0.11747  12.5  6.009   82.9  311.0     15.2  396.90  13.27    18.9  0.0\n",
              "12  0.09378  12.5  5.889   39.0  311.0     15.2  390.50  15.71    21.7  0.0\n",
              "13  0.62976   0.0  5.949   61.8  307.0     21.0  396.90   8.26    20.4  0.0\n",
              "14  0.63796   0.0  6.096   84.5  307.0     21.0  380.02  10.26    18.2  0.0"
            ]
          },
          "metadata": {
            "tags": []
          },
          "execution_count": 87
        }
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "G7z6LKoxpwXv",
        "colab_type": "code",
        "colab": {
          "base_uri": "https://localhost:8080/",
          "height": 142
        },
        "outputId": "069f1edc-5b7e-47c2-b74a-63d47492b1a5"
      },
      "source": [
        "if len(df_byCRIM) > 10:\n",
        "   df_client = df_byCRIM[:10]\n",
        "   df_listings = df_byCRIM[10:]\n",
        "   \n",
        "\n",
        "df_new = pd.concat([df_client, df] ,axis=0)\n",
        "X = df_new.drop(['own'],axis=1) # Features\n",
        "y = df_new['own'] # Target variable\n",
        "\n",
        "def non_shuffling_train_test_split(X, y, test_size):\n",
        "    i = int((1 - test_size) * X.shape[0]) + 1\n",
        "    X_train, X_test = np.split(X, [i])\n",
        "    y_train, y_test = np.split(y, [i])\n",
        "    return X_train, X_test, y_train, y_test\n",
        "\n",
        "\n",
        "X_train, X_test, y_train, y_test = non_shuffling_train_test_split(X, y, test_size=0.85)\n",
        "\n",
        "X_train.head(3)"
      ],
      "execution_count": 88,
      "outputs": [
        {
          "output_type": "execute_result",
          "data": {
            "text/html": [
              "<div>\n",
              "<style scoped>\n",
              "    .dataframe tbody tr th:only-of-type {\n",
              "        vertical-align: middle;\n",
              "    }\n",
              "\n",
              "    .dataframe tbody tr th {\n",
              "        vertical-align: top;\n",
              "    }\n",
              "\n",
              "    .dataframe thead th {\n",
              "        text-align: right;\n",
              "    }\n",
              "</style>\n",
              "<table border=\"1\" class=\"dataframe\">\n",
              "  <thead>\n",
              "    <tr style=\"text-align: right;\">\n",
              "      <th></th>\n",
              "      <th>CRIM</th>\n",
              "      <th>ZN</th>\n",
              "      <th>RM</th>\n",
              "      <th>AGE</th>\n",
              "      <th>TAX</th>\n",
              "      <th>PTRATIO</th>\n",
              "      <th>B</th>\n",
              "      <th>LSTAT</th>\n",
              "      <th>target</th>\n",
              "    </tr>\n",
              "  </thead>\n",
              "  <tbody>\n",
              "    <tr>\n",
              "      <th>0</th>\n",
              "      <td>0.00632</td>\n",
              "      <td>18.0</td>\n",
              "      <td>6.575</td>\n",
              "      <td>65.2</td>\n",
              "      <td>296.0</td>\n",
              "      <td>15.3</td>\n",
              "      <td>396.90</td>\n",
              "      <td>4.98</td>\n",
              "      <td>24.0</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <th>284</th>\n",
              "      <td>0.00906</td>\n",
              "      <td>90.0</td>\n",
              "      <td>7.088</td>\n",
              "      <td>20.8</td>\n",
              "      <td>285.0</td>\n",
              "      <td>15.3</td>\n",
              "      <td>394.72</td>\n",
              "      <td>7.85</td>\n",
              "      <td>32.2</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <th>285</th>\n",
              "      <td>0.01096</td>\n",
              "      <td>55.0</td>\n",
              "      <td>6.453</td>\n",
              "      <td>31.9</td>\n",
              "      <td>300.0</td>\n",
              "      <td>15.3</td>\n",
              "      <td>394.72</td>\n",
              "      <td>8.23</td>\n",
              "      <td>22.0</td>\n",
              "    </tr>\n",
              "  </tbody>\n",
              "</table>\n",
              "</div>"
            ],
            "text/plain": [
              "        CRIM    ZN     RM   AGE    TAX  PTRATIO       B  LSTAT  target\n",
              "0    0.00632  18.0  6.575  65.2  296.0     15.3  396.90   4.98    24.0\n",
              "284  0.00906  90.0  7.088  20.8  285.0     15.3  394.72   7.85    32.2\n",
              "285  0.01096  55.0  6.453  31.9  300.0     15.3  394.72   8.23    22.0"
            ]
          },
          "metadata": {
            "tags": []
          },
          "execution_count": 88
        }
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "X2L-fz2opwa1",
        "colab_type": "code",
        "colab": {}
      },
      "source": [
        "from sklearn.neural_network import BernoulliRBM\n",
        "from sklearn.pipeline import Pipeline\n",
        "from sklearn import linear_model, datasets, metrics\n",
        "\n",
        "logistic = linear_model.LogisticRegression(solver='newton-cg', tol=1,\n",
        "                                           multi_class='multinomial')\n",
        "\n",
        "rbm = BernoulliRBM(random_state=0, verbose=True)\n",
        "rbm_features_classifier = Pipeline(\n",
        "    steps=[('rbm', rbm), ('logistic', logistic)])"
      ],
      "execution_count": 0,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "qVDW7KQrpwdf",
        "colab_type": "code",
        "colab": {
          "base_uri": "https://localhost:8080/",
          "height": 425
        },
        "outputId": "47fcb6e5-c613-4679-f846-089ccccdc1af"
      },
      "source": [
        "rbm_features_classifier.fit(X_train, y_train)"
      ],
      "execution_count": 90,
      "outputs": [
        {
          "output_type": "stream",
          "text": [
            "[BernoulliRBM] Iteration 1, pseudo-likelihood = -2239.65, time = 0.01s\n",
            "[BernoulliRBM] Iteration 2, pseudo-likelihood = -5028.07, time = 0.01s\n",
            "[BernoulliRBM] Iteration 3, pseudo-likelihood = -7809.52, time = 0.00s\n",
            "[BernoulliRBM] Iteration 4, pseudo-likelihood = -10589.56, time = 0.00s\n",
            "[BernoulliRBM] Iteration 5, pseudo-likelihood = -13369.60, time = 0.00s\n",
            "[BernoulliRBM] Iteration 6, pseudo-likelihood = -16147.02, time = 0.00s\n",
            "[BernoulliRBM] Iteration 7, pseudo-likelihood = -18931.10, time = 0.00s\n",
            "[BernoulliRBM] Iteration 8, pseudo-likelihood = -21712.89, time = 0.00s\n",
            "[BernoulliRBM] Iteration 9, pseudo-likelihood = -24492.97, time = 0.00s\n",
            "[BernoulliRBM] Iteration 10, pseudo-likelihood = -27281.41, time = 0.01s\n"
          ],
          "name": "stdout"
        },
        {
          "output_type": "execute_result",
          "data": {
            "text/plain": [
              "Pipeline(memory=None,\n",
              "         steps=[('rbm',\n",
              "                 BernoulliRBM(batch_size=10, learning_rate=0.1,\n",
              "                              n_components=256, n_iter=10, random_state=0,\n",
              "                              verbose=True)),\n",
              "                ('logistic',\n",
              "                 LogisticRegression(C=1.0, class_weight=None, dual=False,\n",
              "                                    fit_intercept=True, intercept_scaling=1,\n",
              "                                    l1_ratio=None, max_iter=100,\n",
              "                                    multi_class='multinomial', n_jobs=None,\n",
              "                                    penalty='l2', random_state=None,\n",
              "                                    solver='newton-cg', tol=1, verbose=0,\n",
              "                                    warm_start=False))],\n",
              "         verbose=False)"
            ]
          },
          "metadata": {
            "tags": []
          },
          "execution_count": 90
        }
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "b0hZhlydpwgj",
        "colab_type": "code",
        "colab": {
          "base_uri": "https://localhost:8080/",
          "height": 238
        },
        "outputId": "31dd0b55-1ef5-4717-b4ac-457b88d5d41a"
      },
      "source": [
        "y_pred = rbm_features_classifier.predict(X_test)\n",
        "print(\"Logistic regression using RBM features:\\n%s\\n\" % (\n",
        "    metrics.classification_report(y_test, y_pred)))"
      ],
      "execution_count": 91,
      "outputs": [
        {
          "output_type": "stream",
          "text": [
            "Logistic regression using RBM features:\n",
            "              precision    recall  f1-score   support\n",
            "\n",
            "         0.0       0.97      1.00      0.98       424\n",
            "         1.0       0.00      0.00      0.00        14\n",
            "\n",
            "    accuracy                           0.97       438\n",
            "   macro avg       0.48      0.50      0.49       438\n",
            "weighted avg       0.94      0.97      0.95       438\n",
            "\n",
            "\n"
          ],
          "name": "stdout"
        },
        {
          "output_type": "stream",
          "text": [
            "/usr/local/lib/python3.6/dist-packages/sklearn/metrics/classification.py:1437: UndefinedMetricWarning: Precision and F-score are ill-defined and being set to 0.0 in labels with no predicted samples.\n",
            "  'precision', 'predicted', average, warn_for)\n"
          ],
          "name": "stderr"
        }
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "YWU1x-JOpwlh",
        "colab_type": "code",
        "colab": {}
      },
      "source": [
        ""
      ],
      "execution_count": 0,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "4W214Y_kpwoi",
        "colab_type": "code",
        "colab": {}
      },
      "source": [
        ""
      ],
      "execution_count": 0,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "Rmf9DKFUpwjQ",
        "colab_type": "code",
        "colab": {}
      },
      "source": [
        ""
      ],
      "execution_count": 0,
      "outputs": []
    }
  ]
}